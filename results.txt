PS C:\Users\benva\OneDrive\Desktop\AI-ASL> python -m tune --n-trials 20 --epochs 10
19:40:08 INFO - 
==================================
| TUNE: OPTUNA (Fixed aug=False) |
==================================
[I 2025-10-27 19:40:08,855] A new study created in memory with name: no-name-e895392c-9e0b-41f8-bdc4-2c161bc9bdf7
19:40:08 INFO - 
===============
| ENSURE DATA |
===============
19:40:08 INFO - Wrote class mapping to data\class_indices.json
19:40:15 INFO - 
=========
| TRAIN |
=========
19:40:15 INFO - Args: {'train_dir': WindowsPath('data/asl_alphabet_train'), 'test_dir': WindowsPath('data/asl_alphabet_test'), 'val_ratio': 0.1, 'subset_per_class': 300, 'epochs': 10, 'batch_size': 128, 'lr': 0.0003569941329738344, 'weight_decay': 1.2295569860283645e-06, 'patience': 3, 'model': 'cnn_small', 'aug': False, 'size': 128, 'num_workers': 2, 'class_weights': False, 'dropout': 0.2481357265122731, 'num_blocks': 4, 'activation': 'gelu', 'seed': 42, 'use_kaggle': False, 'artifacts_root': WindowsPath('artifacts/asl_runs/hp-tuning')}
19:40:15 INFO - Class distribution (train): {'A': 300, 'B': 300, 'C': 300, 'D': 300, 'E': 300, 'F': 300, 'G': 300, 'H': 300, 'I': 300, 'J': 300, 'K': 300, 'L': 300, 'M': 300, 'N': 300, 'O': 300, 'P': 300, 'Q': 300, 'R': 300, 'S': 300, 'T': 300, 'U': 300, 'V': 300, 'W': 300, 'X': 300, 'Y': 300, 'Z': 300, 'del': 300, 'nothing': 300, 'space': 300}
19:40:15 INFO - Class distribution (val):   {'A': 300, 'B': 300, 'C': 300, 'D': 300, 'E': 300, 'F': 300, 'G': 300, 'H': 300, 'I': 300, 'J': 300, 'K': 300, 'L': 300, 'M': 300, 'N': 300, 'O': 300, 'P': 300, 'Q': 300, 'R': 300, 'S': 300, 'T': 300, 'U': 300, 'V': 300, 'W': 300, 'X': 300, 'Y': 300, 'Z': 300, 'del': 300, 'nothing': 300, 'space': 300}
19:40:16 INFO - Dataset sizes: train=8700, val=8700, test=26
19:40:16 INFO - Model: CNNSmall (blocks=4, act=gelu)
19:40:16 INFO - Device: cuda
19:40:16 INFO - Epoch 1/10
19:40:55 INFO - Train: loss=2.9946 acc=0.1875 | Val: loss=2.4768 acc=0.3872 macroF1=0.3169
19:40:56 INFO - New best macro-F1 0.3169 at epoch 1. Checkpoint saved.
19:40:56 INFO - Epoch 2/10
19:41:35 INFO - Train: loss=2.0428 acc=0.4860 | Val: loss=1.7183 acc=0.5771 macroF1=0.5326
19:41:36 INFO - New best macro-F1 0.5326 at epoch 2. Checkpoint saved.
19:41:36 INFO - Epoch 3/10
19:42:17 INFO - Train: loss=1.4109 acc=0.6559 | Val: loss=1.1971 acc=0.7003 macroF1=0.6901
19:42:17 INFO - New best macro-F1 0.6901 at epoch 3. Checkpoint saved.
19:42:17 INFO - Epoch 4/10
19:42:57 INFO - Train: loss=0.9937 acc=0.7902 | Val: loss=0.9098 acc=0.8187 macroF1=0.8122
19:42:58 INFO - New best macro-F1 0.8122 at epoch 4. Checkpoint saved.
19:42:58 INFO - Epoch 5/10
19:43:38 INFO - Train: loss=0.6958 acc=0.8763 | Val: loss=0.6714 acc=0.8249 macroF1=0.8229
19:43:39 INFO - New best macro-F1 0.8229 at epoch 5. Checkpoint saved.
19:43:39 INFO - Epoch 6/10
19:44:20 INFO - Train: loss=0.4869 acc=0.9299 | Val: loss=0.5217 acc=0.8922 macroF1=0.8929
19:44:20 INFO - New best macro-F1 0.8929 at epoch 6. Checkpoint saved.
19:44:20 INFO - Epoch 7/10
19:45:01 INFO - Train: loss=0.3343 acc=0.9576 | Val: loss=0.5701 acc=0.8162 macroF1=0.7998
19:45:01 INFO - No improvement (1/3 patience).
19:45:01 INFO - Epoch 8/10
19:47:12 INFO - Train: loss=0.2370 acc=0.9801 | Val: loss=0.3324 acc=0.9378 macroF1=0.9348
19:47:13 INFO - New best macro-F1 0.9348 at epoch 8. Checkpoint saved.
19:47:13 INFO - Epoch 9/10
19:47:55 INFO - Train: loss=0.1667 acc=0.9880 | Val: loss=0.2875 acc=0.9490 macroF1=0.9496
19:47:55 INFO - New best macro-F1 0.9496 at epoch 9. Checkpoint saved.
19:47:55 INFO - Epoch 10/10
19:48:37 INFO - Train: loss=0.1187 acc=0.9930 | Val: loss=0.1875 acc=0.9547 macroF1=0.9531
19:48:38 INFO - New best macro-F1 0.9531 at epoch 10. Checkpoint saved.
19:48:38 INFO - Training completed. Artifacts at: artifacts\asl_runs\hp-tuning\2025-10-27_19-40-15__train-cnn_small_lr0.000356994_b128_bl4_act-gelu_dr0.248136_ep10_sz128_sub300
[I 2025-10-27 19:48:38,177] Trial 0 finished with value: 0.9531052627114078 and parameters: {'lr': 0.0003569941329738344, 'weight_decay': 1.2295569860283645e-06, 'dropout': 0.2481357265122731, 'size': 128, 'subset_per_class': 300, 'num_blocks': 4, 'activation': 'gelu', 'batch_size': 128}. Best is trial 0 with value: 0.9531052627114078.
19:48:38 INFO -
===============
| ENSURE DATA |
===============
19:48:38 INFO - Wrote class mapping to data\class_indices.json
19:48:45 INFO - 
=========
| TRAIN |
=========
19:48:45 INFO - Args: {'train_dir': WindowsPath('data/asl_alphabet_train'), 'test_dir': WindowsPath('data/asl_alphabet_test'), 'val_ratio': 0.1, 'subset_per_class': 300, 'epochs': 10, 'batch_size': 128, 'lr': 0.001860325499974429, 'weight_decay': 3.4285265680338526e-06, 'patience': 3, 'model': 'cnn_small', 'aug': False, 'size': 128, 'num_workers': 2, 'class_weights': False, 'dropout': 0.08397637809619285, 'num_blocks': 4, 'activation': 'relu', 'seed': 42, 'use_kaggle': False, 'artifacts_root': WindowsPath('artifacts/asl_runs/hp-tuning')}
19:48:45 INFO - Class distribution (train): {'A': 300, 'B': 300, 'C': 300, 'D': 300, 'E': 300, 'F': 300, 'G': 300, 'H': 300, 'I': 300, 'J': 300, 'K': 300, 'L': 300, 'M': 300, 'N': 300, 'O': 300, 'P': 300, 'Q': 300, 'R': 300, 'S': 300, 'T': 300, 'U': 300, 'V': 300, 'W': 300, 'X': 300, 'Y': 300, 'Z': 300, 'del': 300, 'nothing': 300, 'space': 300}
19:48:45 INFO - Class distribution (val):   {'A': 300, 'B': 300, 'C': 300, 'D': 300, 'E': 300, 'F': 300, 'G': 300, 'H': 300, 'I': 300, 'J': 300, 'K': 300, 'L': 300, 'M': 300, 'N': 300, 'O': 300, 'P': 300, 'Q': 300, 'R': 300, 'S': 300, 'T': 300, 'U': 300, 'V': 300, 'W': 300, 'X': 300, 'Y': 300, 'Z': 300, 'del': 300, 'nothing': 300, 'space': 300}
19:48:46 INFO - Dataset sizes: train=8700, val=8700, test=26
19:48:46 INFO - Model: CNNSmall (blocks=4, act=relu)
19:48:46 INFO - Device: cuda
19:48:46 INFO - Epoch 1/10
19:49:28 INFO - Train: loss=2.5500 acc=0.2689 | Val: loss=1.8700 acc=0.4538 macroF1=0.4127                                                                                                                                 
19:49:29 INFO - New best macro-F1 0.4127 at epoch 1. Checkpoint saved.
19:49:29 INFO - Epoch 2/10
19:50:10 INFO - Train: loss=1.1377 acc=0.6690 | Val: loss=1.3374 acc=0.5374 macroF1=0.5098                                                                                                                                 
19:50:11 INFO - New best macro-F1 0.5098 at epoch 2. Checkpoint saved.
19:50:11 INFO - Epoch 3/10
19:50:53 INFO - Train: loss=0.5866 acc=0.8378 | Val: loss=0.6992 acc=0.7498 macroF1=0.7486                                                                                                                                 
19:50:53 INFO - New best macro-F1 0.7486 at epoch 3. Checkpoint saved.
19:50:53 INFO - Epoch 4/10
19:51:34 INFO - Train: loss=0.3002 acc=0.9292 | Val: loss=0.3421 acc=0.9147 macroF1=0.9111                                                                                                                                 
19:51:35 INFO - New best macro-F1 0.9111 at epoch 4. Checkpoint saved.
19:51:35 INFO - Epoch 5/10
19:52:17 INFO - Train: loss=0.1466 acc=0.9739 | Val: loss=0.1812 acc=0.9515 macroF1=0.9513                                                                                                                                 
19:52:17 INFO - New best macro-F1 0.9513 at epoch 5. Checkpoint saved.
19:52:17 INFO - Epoch 6/10
19:52:58 INFO - Train: loss=0.0785 acc=0.9887 | Val: loss=0.1281 acc=0.9672 macroF1=0.9676                                                                                                                                 
19:52:59 INFO - New best macro-F1 0.9676 at epoch 6. Checkpoint saved.
19:52:59 INFO - Epoch 7/10
19:53:41 INFO - Train: loss=0.0362 acc=0.9968 | Val: loss=0.1157 acc=0.9715 macroF1=0.9709                                                                                                                                 
19:53:41 INFO - New best macro-F1 0.9709 at epoch 7. Checkpoint saved.
19:53:41 INFO - Epoch 8/10
19:54:22 INFO - Train: loss=0.0242 acc=0.9983 | Val: loss=0.0346 acc=0.9966 macroF1=0.9966                                                                                                                                 
19:54:23 INFO - New best macro-F1 0.9966 at epoch 8. Checkpoint saved.
19:54:23 INFO - Epoch 9/10
19:55:05 INFO - Train: loss=0.0161 acc=0.9990 | Val: loss=0.1644 acc=0.9464 macroF1=0.9456                                                                                                                                 
19:55:05 INFO - No improvement (1/3 patience).
19:55:05 INFO - Epoch 10/10
19:55:47 INFO - Train: loss=0.0159 acc=0.9989 | Val: loss=0.0458 acc=0.9887 macroF1=0.9888                                                                                                                                 
19:55:47 INFO - No improvement (2/3 patience).
19:55:47 INFO - Training completed. Artifacts at: artifacts\asl_runs\hp-tuning\2025-10-27_19-48-45__train-cnn_small_lr0.00186033_b128_bl4_act-relu_dr0.0839764_ep10_sz128_sub300
[I 2025-10-27 19:55:47,204] Trial 1 finished with value: 0.9965513787447793 and parameters: {'lr': 0.001860325499974429, 'weight_decay': 3.4285265680338526e-06, 'dropout': 0.08397637809619285, 'size': 128, 'subset_per_class': 300, 'num_blocks': 4, 'activation': 'relu', 'batch_size': 128}. Best is trial 1 with value: 0.9965513787447793.
19:55:47 INFO -
===============
| ENSURE DATA |
===============
19:55:47 INFO - Wrote class mapping to data\class_indices.json
19:55:54 INFO - 
=========
| TRAIN |
=========
19:55:54 INFO - Args: {'train_dir': WindowsPath('data/asl_alphabet_train'), 'test_dir': WindowsPath('data/asl_alphabet_test'), 'val_ratio': 0.1, 'subset_per_class': 300, 'epochs': 10, 'batch_size': 32, 'lr': 0.00032166635939426795, 'weight_decay': 1.4395920497786838e-05, 'patience': 3, 'model': 'cnn_small', 'aug': False, 'size': 128, 'num_workers': 2, 'class_weights': False, 'dropout': 0.38635491114403725, 'num_blocks': 3, 'activation': 'relu', 'seed': 42, 'use_kaggle': False, 'artifacts_root': WindowsPath('artifacts/asl_runs/hp-tuning')}
19:55:54 INFO - Class distribution (train): {'A': 300, 'B': 300, 'C': 300, 'D': 300, 'E': 300, 'F': 300, 'G': 300, 'H': 300, 'I': 300, 'J': 300, 'K': 300, 'L': 300, 'M': 300, 'N': 300, 'O': 300, 'P': 300, 'Q': 300, 'R': 300, 'S': 300, 'T': 300, 'U': 300, 'V': 300, 'W': 300, 'X': 300, 'Y': 300, 'Z': 300, 'del': 300, 'nothing': 300, 'space': 300}
19:55:54 INFO - Class distribution (val):   {'A': 300, 'B': 300, 'C': 300, 'D': 300, 'E': 300, 'F': 300, 'G': 300, 'H': 300, 'I': 300, 'J': 300, 'K': 300, 'L': 300, 'M': 300, 'N': 300, 'O': 300, 'P': 300, 'Q': 300, 'R': 300, 'S': 300, 'T': 300, 'U': 300, 'V': 300, 'W': 300, 'X': 300, 'Y': 300, 'Z': 300, 'del': 300, 'nothing': 300, 'space': 300}
19:55:55 INFO - Dataset sizes: train=8700, val=8700, test=26
19:55:55 INFO - Model: CNNSmall (blocks=3, act=relu)
19:55:55 INFO - Device: cuda
19:55:55 INFO - Epoch 1/10
19:56:34 INFO - Train: loss=3.1325 acc=0.1001 | Val: loss=2.7964 acc=0.1664 macroF1=0.1110                                                                                                                                 
19:56:35 INFO - New best macro-F1 0.1110 at epoch 1. Checkpoint saved.
19:56:35 INFO - Epoch 2/10
19:57:14 INFO - Train: loss=2.6088 acc=0.2480 | Val: loss=2.4366 acc=0.2986 macroF1=0.2492                                                                                                                                 
19:57:15 INFO - New best macro-F1 0.2492 at epoch 2. Checkpoint saved.
19:57:15 INFO - Epoch 3/10
19:57:54 INFO - Train: loss=2.1771 acc=0.3745 | Val: loss=1.9080 acc=0.4992 macroF1=0.4727                                                                                                                                 
19:57:54 INFO - New best macro-F1 0.4727 at epoch 3. Checkpoint saved.
19:57:54 INFO - Epoch 4/10
19:58:34 INFO - Train: loss=1.8369 acc=0.4754 | Val: loss=1.6026 acc=0.5456 macroF1=0.5232                                                                                                                                 
19:58:35 INFO - New best macro-F1 0.5232 at epoch 4. Checkpoint saved.
19:58:35 INFO - Epoch 5/10
19:59:14 INFO - Train: loss=1.5676 acc=0.5487 | Val: loss=1.3754 acc=0.6097 macroF1=0.5946                                                                                                                                 
19:59:15 INFO - New best macro-F1 0.5946 at epoch 5. Checkpoint saved.
19:59:15 INFO - Epoch 6/10
19:59:55 INFO - Train: loss=1.3838 acc=0.6002 | Val: loss=1.2713 acc=0.5907 macroF1=0.5605                                                                                                                                 
19:59:55 INFO - No improvement (1/3 patience).
19:59:55 INFO - Epoch 7/10
20:00:34 INFO - Train: loss=1.2185 acc=0.6539 | Val: loss=1.2036 acc=0.6060 macroF1=0.5633                                                                                                                                 
20:00:34 INFO - No improvement (2/3 patience).
20:00:34 INFO - Epoch 8/10
20:01:14 INFO - Train: loss=1.0690 acc=0.7011 | Val: loss=0.8724 acc=0.8013 macroF1=0.7884                                                                                                                                 
20:01:15 INFO - New best macro-F1 0.7884 at epoch 8. Checkpoint saved.
20:01:15 INFO - Epoch 9/10
20:01:55 INFO - Train: loss=0.9535 acc=0.7385 | Val: loss=0.7978 acc=0.7809 macroF1=0.7736                                                                                                                                 
20:01:55 INFO - No improvement (1/3 patience).
20:01:55 INFO - Epoch 10/10
20:02:34 INFO - Train: loss=0.8486 acc=0.7740 | Val: loss=0.8031 acc=0.7752 macroF1=0.7691                                                                                                                                 
20:02:34 INFO - No improvement (2/3 patience).
20:02:34 INFO - Training completed. Artifacts at: artifacts\asl_runs\hp-tuning\2025-10-27_19-55-54__train-cnn_small_lr0.000321666_b32_bl3_act-relu_dr0.386355_ep10_sz128_sub300
[I 2025-10-27 20:02:34,710] Trial 2 finished with value: 0.7883601084779369 and parameters: {'lr': 0.00032166635939426795, 'weight_decay': 1.4395920497786838e-05, 'dropout': 0.38635491114403725, 'size': 128, 'subset_per_class': 300, 'num_blocks': 3, 'activation': 'relu', 'batch_size': 32}. Best is trial 1 with value: 0.9965513787447793.
20:02:34 INFO -
===============
| ENSURE DATA |
===============
20:02:34 INFO - Wrote class mapping to data\class_indices.json
20:02:41 INFO - 
=========
| TRAIN |
=========
20:02:41 INFO - Args: {'train_dir': WindowsPath('data/asl_alphabet_train'), 'test_dir': WindowsPath('data/asl_alphabet_test'), 'val_ratio': 0.1, 'subset_per_class': 300, 'epochs': 10, 'batch_size': 32, 'lr': 0.00014191421263407748, 'weight_decay': 0.00020027021983195478, 'patience': 3, 'model': 'cnn_small', 'aug': False, 'size': 128, 'num_workers': 2, 'class_weights': False, 'dropout': 0.22248522068889015, 'num_blocks': 4, 'activation': 'relu', 'seed': 42, 'use_kaggle': False, 'artifacts_root': WindowsPath('artifacts/asl_runs/hp-tuning')}
20:02:41 INFO - Class distribution (train): {'A': 300, 'B': 300, 'C': 300, 'D': 300, 'E': 300, 'F': 300, 'G': 300, 'H': 300, 'I': 300, 'J': 300, 'K': 300, 'L': 300, 'M': 300, 'N': 300, 'O': 300, 'P': 300, 'Q': 300, 'R': 300, 'S': 300, 'T': 300, 'U': 300, 'V': 300, 'W': 300, 'X': 300, 'Y': 300, 'Z': 300, 'del': 300, 'nothing': 300, 'space': 300}
20:02:41 INFO - Class distribution (val):   {'A': 300, 'B': 300, 'C': 300, 'D': 300, 'E': 300, 'F': 300, 'G': 300, 'H': 300, 'I': 300, 'J': 300, 'K': 300, 'L': 300, 'M': 300, 'N': 300, 'O': 300, 'P': 300, 'Q': 300, 'R': 300, 'S': 300, 'T': 300, 'U': 300, 'V': 300, 'W': 300, 'X': 300, 'Y': 300, 'Z': 300, 'del': 300, 'nothing': 300, 'space': 300}
20:02:42 INFO - Dataset sizes: train=8700, val=8700, test=26
20:02:42 INFO - Model: CNNSmall (blocks=4, act=relu)
20:02:42 INFO - Device: cuda
20:02:42 INFO - Epoch 1/10
20:03:23 INFO - Train: loss=2.9641 acc=0.1939 | Val: loss=2.5094 acc=0.3755 macroF1=0.3130                                                                                                                                 
20:03:24 INFO - New best macro-F1 0.3130 at epoch 1. Checkpoint saved.
20:03:24 INFO - Epoch 2/10
20:04:05 INFO - Train: loss=2.1165 acc=0.4567 | Val: loss=2.0698 acc=0.3308 macroF1=0.2836                                                                                                                                 
20:04:05 INFO - No improvement (1/3 patience).
20:04:05 INFO - Epoch 3/10
20:04:46 INFO - Train: loss=1.5397 acc=0.6146 | Val: loss=1.4471 acc=0.5656 macroF1=0.5350                                                                                                                                 
20:04:47 INFO - New best macro-F1 0.5350 at epoch 3. Checkpoint saved.
20:04:47 INFO - Epoch 4/10
20:05:27 INFO - Train: loss=1.1637 acc=0.7409 | Val: loss=1.3401 acc=0.5640 macroF1=0.5346                                                                                                                                 
20:05:27 INFO - No improvement (1/3 patience).
20:05:27 INFO - Epoch 5/10
20:06:08 INFO - Train: loss=0.8820 acc=0.8216 | Val: loss=0.8310 acc=0.8086 macroF1=0.8028                                                                                                                                 
20:06:08 INFO - New best macro-F1 0.8028 at epoch 5. Checkpoint saved.
20:06:08 INFO - Epoch 6/10
20:06:49 INFO - Train: loss=0.6692 acc=0.8808 | Val: loss=0.8699 acc=0.7439 macroF1=0.7397                                                                                                                                 
20:06:49 INFO - No improvement (1/3 patience).
20:06:49 INFO - Epoch 7/10
20:07:30 INFO - Train: loss=0.5035 acc=0.9229 | Val: loss=0.3810 acc=0.9439 macroF1=0.9419                                                                                                                                 
20:07:30 INFO - New best macro-F1 0.9419 at epoch 7. Checkpoint saved.
20:07:30 INFO - Epoch 8/10
20:08:11 INFO - Train: loss=0.3712 acc=0.9482 | Val: loss=0.4908 acc=0.8738 macroF1=0.8719                                                                                                                                 
20:08:11 INFO - No improvement (1/3 patience).
20:08:11 INFO - Epoch 9/10
20:08:52 INFO - Train: loss=0.2851 acc=0.9632 | Val: loss=0.3703 acc=0.9202 macroF1=0.9195                                                                                                                                 
20:08:52 INFO - No improvement (2/3 patience).
20:08:52 INFO - Epoch 10/10
20:09:33 INFO - Train: loss=0.2161 acc=0.9756 | Val: loss=0.2528 acc=0.9505 macroF1=0.9496                                                                                                                                 
20:09:33 INFO - New best macro-F1 0.9496 at epoch 10. Checkpoint saved.
20:09:33 INFO - Training completed. Artifacts at: artifacts\asl_runs\hp-tuning\2025-10-27_20-02-41__train-cnn_small_lr0.000141914_b32_bl4_act-relu_dr0.222485_ep10_sz128_sub300
[I 2025-10-27 20:09:33,718] Trial 3 finished with value: 0.9496071942457517 and parameters: {'lr': 0.00014191421263407748, 'weight_decay': 0.00020027021983195478, 'dropout': 0.22248522068889015, 'size': 128, 'subset_per_class': 300, 'num_blocks': 4, 'activation': 'relu', 'batch_size': 32}. Best is trial 1 with value: 0.9965513787447793.
20:09:33 INFO -
===============
| ENSURE DATA |
===============
20:09:33 INFO - Wrote class mapping to data\class_indices.json
20:09:40 INFO - 
=========
| TRAIN |
=========
20:09:40 INFO - Args: {'train_dir': WindowsPath('data/asl_alphabet_train'), 'test_dir': WindowsPath('data/asl_alphabet_test'), 'val_ratio': 0.1, 'subset_per_class': 300, 'epochs': 10, 'batch_size': 64, 'lr': 0.0005821426414158898, 'weight_decay': 7.568276484994108e-06, 'patience': 3, 'model': 'cnn_small', 'aug': False, 'size': 128, 'num_workers': 2, 'class_weights': False, 'dropout': 0.35490414032451634, 'num_blocks': 2, 'activation': 'gelu', 'seed': 42, 'use_kaggle': False, 'artifacts_root': WindowsPath('artifacts/asl_runs/hp-tuning')}
20:09:40 INFO - Class distribution (train): {'A': 300, 'B': 300, 'C': 300, 'D': 300, 'E': 300, 'F': 300, 'G': 300, 'H': 300, 'I': 300, 'J': 300, 'K': 300, 'L': 300, 'M': 300, 'N': 300, 'O': 300, 'P': 300, 'Q': 300, 'R': 300, 'S': 300, 'T': 300, 'U': 300, 'V': 300, 'W': 300, 'X': 300, 'Y': 300, 'Z': 300, 'del': 300, 'nothing': 300, 'space': 300}
20:09:40 INFO - Class distribution (val):   {'A': 300, 'B': 300, 'C': 300, 'D': 300, 'E': 300, 'F': 300, 'G': 300, 'H': 300, 'I': 300, 'J': 300, 'K': 300, 'L': 300, 'M': 300, 'N': 300, 'O': 300, 'P': 300, 'Q': 300, 'R': 300, 'S': 300, 'T': 300, 'U': 300, 'V': 300, 'W': 300, 'X': 300, 'Y': 300, 'Z': 300, 'del': 300, 'nothing': 300, 'space': 300}
20:09:41 INFO - Dataset sizes: train=8700, val=8700, test=26
20:09:41 INFO - Model: CNNSmall (blocks=2, act=gelu)
20:09:41 INFO - Device: cuda
20:09:41 INFO - Epoch 1/10
20:10:19 INFO - Train: loss=3.2864 acc=0.0560 | Val: loss=3.1445 acc=0.0838 macroF1=0.0376                                                                                                                                 
20:10:20 INFO - New best macro-F1 0.0376 at epoch 1. Checkpoint saved.
20:10:20 INFO - Epoch 2/10
20:10:58 INFO - Train: loss=3.0418 acc=0.1068 | Val: loss=2.9367 acc=0.1423 macroF1=0.0958                                                                                                                                 
20:10:58 INFO - New best macro-F1 0.0958 at epoch 2. Checkpoint saved.
20:10:58 INFO - Epoch 3/10
20:11:36 INFO - Train: loss=2.8189 acc=0.1851 | Val: loss=2.7022 acc=0.2394 macroF1=0.1860                                                                                                                                 
20:11:36 INFO - New best macro-F1 0.1860 at epoch 3. Checkpoint saved.
20:11:36 INFO - Epoch 4/10
20:12:14 INFO - Train: loss=2.6220 acc=0.2344 | Val: loss=2.4566 acc=0.3000 macroF1=0.2380                                                                                                                                 
20:12:14 INFO - New best macro-F1 0.2380 at epoch 4. Checkpoint saved.
20:12:14 INFO - Epoch 5/10
20:12:52 INFO - Train: loss=2.4646 acc=0.2697 | Val: loss=2.3278 acc=0.3070 macroF1=0.2573                                                                                                                                 
20:12:53 INFO - New best macro-F1 0.2573 at epoch 5. Checkpoint saved.
20:12:53 INFO - Epoch 6/10
20:13:31 INFO - Train: loss=2.3239 acc=0.3060 | Val: loss=2.2213 acc=0.3977 macroF1=0.3533                                                                                                                                 
20:13:31 INFO - New best macro-F1 0.3533 at epoch 6. Checkpoint saved.
20:13:31 INFO - Epoch 7/10
20:14:08 INFO - Train: loss=2.1995 acc=0.3331 | Val: loss=2.1195 acc=0.3616 macroF1=0.3199                                                                                                                                 
20:14:08 INFO - No improvement (1/3 patience).
20:14:08 INFO - Epoch 8/10
20:14:46 INFO - Train: loss=2.1079 acc=0.3590 | Val: loss=2.0461 acc=0.3848 macroF1=0.3513                                                                                                                                 
20:14:46 INFO - No improvement (2/3 patience).
20:14:46 INFO - Epoch 9/10
20:15:24 INFO - Train: loss=2.0096 acc=0.3915 | Val: loss=1.9447 acc=0.4400 macroF1=0.3971                                                                                                                                 
20:15:25 INFO - New best macro-F1 0.3971 at epoch 9. Checkpoint saved.
20:15:25 INFO - Epoch 10/10
20:16:03 INFO - Train: loss=1.9339 acc=0.4083 | Val: loss=1.7601 acc=0.4952 macroF1=0.4712                                                                                                                                 
20:16:03 INFO - New best macro-F1 0.4712 at epoch 10. Checkpoint saved.
20:16:03 INFO - Training completed. Artifacts at: artifacts\asl_runs\hp-tuning\2025-10-27_20-09-40__train-cnn_small_lr0.000582143_b64_bl2_act-gelu_dr0.354904_ep10_sz128_sub300
[I 2025-10-27 20:16:03,637] Trial 4 finished with value: 0.47120142696313966 and parameters: {'lr': 0.0005821426414158898, 'weight_decay': 7.568276484994108e-06, 'dropout': 0.35490414032451634, 'size': 128, 'subset_per_class': 300, 'num_blocks': 2, 'activation': 'gelu', 'batch_size': 64}. Best is trial 1 with value: 0.9965513787447793.
20:16:03 INFO -
===============
| ENSURE DATA |
===============
20:16:03 INFO - Wrote class mapping to data\class_indices.json
20:16:10 INFO - 
=========
| TRAIN |
=========
20:16:10 INFO - Args: {'train_dir': WindowsPath('data/asl_alphabet_train'), 'test_dir': WindowsPath('data/asl_alphabet_test'), 'val_ratio': 0.1, 'subset_per_class': 300, 'epochs': 10, 'batch_size': 64, 'lr': 0.0010719908834687934, 'weight_decay': 2.00160820023188e-06, 'patience': 3, 'model': 'cnn_small', 'aug': False, 'size': 96, 'num_workers': 2, 'class_weights': False, 'dropout': 0.09817644414365173, 'num_blocks': 3, 'activation': 'gelu', 'seed': 42, 'use_kaggle': False, 'artifacts_root': WindowsPath('artifacts/asl_runs/hp-tuning')}
20:16:10 INFO - Class distribution (train): {'A': 300, 'B': 300, 'C': 300, 'D': 300, 'E': 300, 'F': 300, 'G': 300, 'H': 300, 'I': 300, 'J': 300, 'K': 300, 'L': 300, 'M': 300, 'N': 300, 'O': 300, 'P': 300, 'Q': 300, 'R': 300, 'S': 300, 'T': 300, 'U': 300, 'V': 300, 'W': 300, 'X': 300, 'Y': 300, 'Z': 300, 'del': 300, 'nothing': 300, 'space': 300}
20:16:10 INFO - Class distribution (val):   {'A': 300, 'B': 300, 'C': 300, 'D': 300, 'E': 300, 'F': 300, 'G': 300, 'H': 300, 'I': 300, 'J': 300, 'K': 300, 'L': 300, 'M': 300, 'N': 300, 'O': 300, 'P': 300, 'Q': 300, 'R': 300, 'S': 300, 'T': 300, 'U': 300, 'V': 300, 'W': 300, 'X': 300, 'Y': 300, 'Z': 300, 'del': 300, 'nothing': 300, 'space': 300}
20:16:11 INFO - Dataset sizes: train=8700, val=8700, test=26
20:16:11 INFO - Model: CNNSmall (blocks=3, act=gelu)
20:16:11 INFO - Device: cuda
20:16:11 INFO - Epoch 1/10
20:16:45 INFO - Train: loss=2.6844 acc=0.2377 | Val: loss=2.1363 acc=0.3584 macroF1=0.3188
20:16:46 INFO - New best macro-F1 0.3188 at epoch 1. Checkpoint saved.
20:16:46 INFO - Epoch 2/10
20:17:20 INFO - Train: loss=1.5642 acc=0.5793 | Val: loss=1.2494 acc=0.6641 macroF1=0.6509                                                                                                                                 
20:17:21 INFO - New best macro-F1 0.6509 at epoch 2. Checkpoint saved.
20:17:21 INFO - Epoch 3/10
20:17:55 INFO - Train: loss=0.9659 acc=0.7570 | Val: loss=0.8362 acc=0.7522 macroF1=0.7440                                                                                                                                 
20:17:56 INFO - New best macro-F1 0.7440 at epoch 3. Checkpoint saved.
20:17:56 INFO - Epoch 4/10
20:18:30 INFO - Train: loss=0.6203 acc=0.8516 | Val: loss=0.5443 acc=0.8571 macroF1=0.8530                                                                                                                                 
20:18:30 INFO - New best macro-F1 0.8530 at epoch 4. Checkpoint saved.
20:18:30 INFO - Epoch 5/10
20:19:04 INFO - Train: loss=0.4213 acc=0.9046 | Val: loss=0.5289 acc=0.8491 macroF1=0.8411                                                                                                                                 
20:19:04 INFO - No improvement (1/3 patience).
20:19:04 INFO - Epoch 6/10
20:19:39 INFO - Train: loss=0.2817 acc=0.9508 | Val: loss=0.4492 acc=0.8485 macroF1=0.8422                                                                                                                                 
20:19:39 INFO - No improvement (2/3 patience).
20:19:39 INFO - Epoch 7/10
20:20:13 INFO - Train: loss=0.2066 acc=0.9616 | Val: loss=0.1523 acc=0.9802 macroF1=0.9803                                                                                                                                 
20:20:14 INFO - New best macro-F1 0.9803 at epoch 7. Checkpoint saved.
20:20:14 INFO - Epoch 8/10
20:20:48 INFO - Train: loss=0.1543 acc=0.9737 | Val: loss=0.1887 acc=0.9546 macroF1=0.9546                                                                                                                                 
20:20:48 INFO - No improvement (1/3 patience).
20:20:48 INFO - Epoch 9/10
20:21:22 INFO - Train: loss=0.1109 acc=0.9848 | Val: loss=0.1308 acc=0.9762 macroF1=0.9762                                                                                                                                 
20:21:22 INFO - No improvement (2/3 patience).
20:21:22 INFO - Epoch 10/10
20:21:55 INFO - Train: loss=0.0874 acc=0.9891 | Val: loss=0.1440 acc=0.9623 macroF1=0.9625                                                                                                                                 
20:21:55 INFO - No improvement (3/3 patience).
20:21:55 INFO - Early stopping triggered.
20:21:55 INFO - Training completed. Artifacts at: artifacts\asl_runs\hp-tuning\2025-10-27_20-16-10__train-cnn_small_lr0.00107199_b64_bl3_act-gelu_dr0.0981764_ep10_sub300
[I 2025-10-27 20:21:55,782] Trial 5 finished with value: 0.9802507121051182 and parameters: {'lr': 0.0010719908834687934, 'weight_decay': 2.00160820023188e-06, 'dropout': 0.09817644414365173, 'size': 96, 'subset_per_class': 300, 'num_blocks': 3, 'activation': 'gelu', 'batch_size': 64}. Best is trial 1 with value: 0.9965513787447793.
20:21:55 INFO -
===============
| ENSURE DATA |
===============
20:21:55 INFO - Wrote class mapping to data\class_indices.json
20:22:02 INFO - 
=========
| TRAIN |
=========
20:22:02 INFO - Args: {'train_dir': WindowsPath('data/asl_alphabet_train'), 'test_dir': WindowsPath('data/asl_alphabet_test'), 'val_ratio': 0.1, 'subset_per_class': 300, 'epochs': 10, 'batch_size': 32, 'lr': 0.0003444364873914456, 'weight_decay': 8.337343098660467e-05, 'patience': 3, 'model': 'cnn_small', 'aug': False, 'size': 128, 'num_workers': 2, 'class_weights': False, 'dropout': 0.03763805884197553, 'num_blocks': 3, 'activation': 'relu', 'seed': 42, 'use_kaggle': False, 'artifacts_root': WindowsPath('artifacts/asl_runs/hp-tuning')}
20:22:02 INFO - Class distribution (train): {'A': 300, 'B': 300, 'C': 300, 'D': 300, 'E': 300, 'F': 300, 'G': 300, 'H': 300, 'I': 300, 'J': 300, 'K': 300, 'L': 300, 'M': 300, 'N': 300, 'O': 300, 'P': 300, 'Q': 300, 'R': 300, 'S': 300, 'T': 300, 'U': 300, 'V': 300, 'W': 300, 'X': 300, 'Y': 300, 'Z': 300, 'del': 300, 'nothing': 300, 'space': 300}
20:22:02 INFO - Class distribution (val):   {'A': 300, 'B': 300, 'C': 300, 'D': 300, 'E': 300, 'F': 300, 'G': 300, 'H': 300, 'I': 300, 'J': 300, 'K': 300, 'L': 300, 'M': 300, 'N': 300, 'O': 300, 'P': 300, 'Q': 300, 'R': 300, 'S': 300, 'T': 300, 'U': 300, 'V': 300, 'W': 300, 'X': 300, 'Y': 300, 'Z': 300, 'del': 300, 'nothing': 300, 'space': 300}
20:22:03 INFO - Dataset sizes: train=8700, val=8700, test=26
20:22:03 INFO - Model: CNNSmall (blocks=3, act=relu)
20:22:03 INFO - Device: cuda
20:22:03 INFO - Epoch 1/10
20:22:42 INFO - Train: loss=3.0675 acc=0.1182 | Val: loss=2.6500 acc=0.2280 macroF1=0.1728                                                                                                                                 
20:22:43 INFO - New best macro-F1 0.1728 at epoch 1. Checkpoint saved.
20:22:43 INFO - Epoch 2/10
20:23:23 INFO - Train: loss=2.4258 acc=0.3303 | Val: loss=2.1602 acc=0.4122 macroF1=0.3552                                                                                                                                 
20:23:24 INFO - New best macro-F1 0.3552 at epoch 2. Checkpoint saved.
20:23:24 INFO - Epoch 3/10
20:24:03 INFO - Train: loss=1.9078 acc=0.4777 | Val: loss=1.6771 acc=0.5172 macroF1=0.4755                                                                                                                                 
20:24:04 INFO - New best macro-F1 0.4755 at epoch 3. Checkpoint saved.
20:24:04 INFO - Epoch 4/10
20:24:43 INFO - Train: loss=1.5359 acc=0.5929 | Val: loss=1.3826 acc=0.5964 macroF1=0.5763                                                                                                                                 
20:24:44 INFO - New best macro-F1 0.5763 at epoch 4. Checkpoint saved.
20:24:44 INFO - Epoch 5/10
20:25:23 INFO - Train: loss=1.2521 acc=0.6768 | Val: loss=1.1738 acc=0.6646 macroF1=0.6500                                                                                                                                 
20:25:24 INFO - New best macro-F1 0.6500 at epoch 5. Checkpoint saved.
20:25:24 INFO - Epoch 6/10
20:26:03 INFO - Train: loss=1.0551 acc=0.7425 | Val: loss=1.2852 acc=0.5794 macroF1=0.5449                                                                                                                                 
20:26:03 INFO - No improvement (1/3 patience).
20:26:03 INFO - Epoch 7/10
20:26:43 INFO - Train: loss=0.8848 acc=0.7889 | Val: loss=0.8732 acc=0.7414 macroF1=0.7264                                                                                                                                 
20:26:44 INFO - New best macro-F1 0.7264 at epoch 7. Checkpoint saved.
20:26:44 INFO - Epoch 8/10
20:27:23 INFO - Train: loss=0.7318 acc=0.8375 | Val: loss=0.7287 acc=0.7863 macroF1=0.7704                                                                                                                                 
20:27:23 INFO - New best macro-F1 0.7704 at epoch 8. Checkpoint saved.
20:27:23 INFO - Epoch 9/10
20:28:03 INFO - Train: loss=0.6146 acc=0.8725 | Val: loss=0.5093 acc=0.9009 macroF1=0.8992                                                                                                                                 
20:28:03 INFO - New best macro-F1 0.8992 at epoch 9. Checkpoint saved.
20:28:03 INFO - Epoch 10/10
20:28:42 INFO - Train: loss=0.5163 acc=0.8985 | Val: loss=0.4488 acc=0.9291 macroF1=0.9292                                                                                                                                 
20:28:43 INFO - New best macro-F1 0.9292 at epoch 10. Checkpoint saved.
20:28:43 INFO - Training completed. Artifacts at: artifacts\asl_runs\hp-tuning\2025-10-27_20-22-02__train-cnn_small_lr0.000344436_b32_bl3_act-relu_dr0.0376381_ep10_sz128_sub300
[I 2025-10-27 20:28:43,377] Trial 6 finished with value: 0.9291992812073372 and parameters: {'lr': 0.0003444364873914456, 'weight_decay': 8.337343098660467e-05, 'dropout': 0.03763805884197553, 'size': 128, 'subset_per_class': 300, 'num_blocks': 3, 'activation': 'relu', 'batch_size': 32}. Best is trial 1 with value: 0.9965513787447793.
20:28:43 INFO -
===============
| ENSURE DATA |
===============
20:28:43 INFO - Wrote class mapping to data\class_indices.json
20:28:50 INFO - 
=========
| TRAIN |
=========
20:28:50 INFO - Args: {'train_dir': WindowsPath('data/asl_alphabet_train'), 'test_dir': WindowsPath('data/asl_alphabet_test'), 'val_ratio': 0.1, 'subset_per_class': 300, 'epochs': 10, 'batch_size': 128, 'lr': 0.00017692708918304746, 'weight_decay': 1.0671133823046195e-06, 'patience': 3, 'model': 'cnn_small', 'aug': False, 'size': 128, 'num_workers': 2, 'class_weights': False, 'dropout': 0.09279795248750232, 'num_blocks': 2, 'activation': 'relu', 'seed': 42, 'use_kaggle': False, 'artifacts_root': WindowsPath('artifacts/asl_runs/hp-tuning')}
20:28:50 INFO - Class distribution (train): {'A': 300, 'B': 300, 'C': 300, 'D': 300, 'E': 300, 'F': 300, 'G': 300, 'H': 300, 'I': 300, 'J': 300, 'K': 300, 'L': 300, 'M': 300, 'N': 300, 'O': 300, 'P': 300, 'Q': 300, 'R': 300, 'S': 300, 'T': 300, 'U': 300, 'V': 300, 'W': 300, 'X': 300, 'Y': 300, 'Z': 300, 'del': 300, 'nothing': 300, 'space': 300}
20:28:50 INFO - Class distribution (val):   {'A': 300, 'B': 300, 'C': 300, 'D': 300, 'E': 300, 'F': 300, 'G': 300, 'H': 300, 'I': 300, 'J': 300, 'K': 300, 'L': 300, 'M': 300, 'N': 300, 'O': 300, 'P': 300, 'Q': 300, 'R': 300, 'S': 300, 'T': 300, 'U': 300, 'V': 300, 'W': 300, 'X': 300, 'Y': 300, 'Z': 300, 'del': 300, 'nothing': 300, 'space': 300}
20:28:51 INFO - Dataset sizes: train=8700, val=8700, test=26
20:28:51 INFO - Model: CNNSmall (blocks=2, act=relu)
20:28:51 INFO - Device: cuda
20:28:51 INFO - Epoch 1/10
20:29:29 INFO - Train: loss=3.3601 acc=0.0483 | Val: loss=3.3449 acc=0.0667 macroF1=0.0196                                                                                                                                 
20:29:30 INFO - New best macro-F1 0.0196 at epoch 1. Checkpoint saved.
20:29:30 INFO - Epoch 2/10
20:30:10 INFO - Train: loss=3.3212 acc=0.0640 | Val: loss=3.2849 acc=0.0724 macroF1=0.0233                                                                                                                                 
20:30:10 INFO - New best macro-F1 0.0233 at epoch 2. Checkpoint saved.
20:30:10 INFO - Epoch 3/10
20:30:48 INFO - Train: loss=3.2541 acc=0.0682 | Val: loss=3.2104 acc=0.0748 macroF1=0.0294                                                                                                                                 
20:30:48 INFO - New best macro-F1 0.0294 at epoch 3. Checkpoint saved.
20:30:48 INFO - Epoch 4/10
20:31:26 INFO - Train: loss=3.1702 acc=0.0685 | Val: loss=3.1319 acc=0.0698 macroF1=0.0272                                                                                                                                 
20:31:26 INFO - No improvement (1/3 patience).
20:31:26 INFO - Epoch 5/10
20:32:05 INFO - Train: loss=3.0936 acc=0.0748 | Val: loss=3.0442 acc=0.0799 macroF1=0.0414                                                                                                                                 
20:32:05 INFO - New best macro-F1 0.0414 at epoch 5. Checkpoint saved.
20:32:05 INFO - Epoch 6/10
20:32:43 INFO - Train: loss=3.0323 acc=0.0940 | Val: loss=2.9949 acc=0.0931 macroF1=0.0502                                                                                                                                 
20:32:44 INFO - New best macro-F1 0.0502 at epoch 6. Checkpoint saved.
20:32:44 INFO - Epoch 7/10
20:33:22 INFO - Train: loss=2.9813 acc=0.1144 | Val: loss=2.9464 acc=0.1564 macroF1=0.1178                                                                                                                                 
20:33:23 INFO - New best macro-F1 0.1178 at epoch 7. Checkpoint saved.
20:33:23 INFO - Epoch 8/10
20:34:02 INFO - Train: loss=2.9409 acc=0.1414 | Val: loss=2.8983 acc=0.1922 macroF1=0.1577                                                                                                                                 
20:34:03 INFO - New best macro-F1 0.1577 at epoch 8. Checkpoint saved.
20:34:03 INFO - Epoch 9/10
20:34:41 INFO - Train: loss=2.8941 acc=0.1868 | Val: loss=2.8610 acc=0.1877 macroF1=0.1432                                                                                                                                 
20:34:41 INFO - No improvement (1/3 patience).
20:34:41 INFO - Epoch 10/10
20:35:19 INFO - Train: loss=2.8542 acc=0.1907 | Val: loss=2.8502 acc=0.1861 macroF1=0.1427                                                                                                                                 
20:35:19 INFO - No improvement (2/3 patience).
20:35:19 INFO - Training completed. Artifacts at: artifacts\asl_runs\hp-tuning\2025-10-27_20-28-50__train-cnn_small_lr0.000176927_b128_bl2_act-relu_dr0.092798_ep10_sz128_sub300
[I 2025-10-27 20:35:19,093] Trial 7 finished with value: 0.1576715993077732 and parameters: {'lr': 0.00017692708918304746, 'weight_decay': 1.0671133823046195e-06, 'dropout': 0.09279795248750232, 'size': 128, 'subset_per_class': 300, 'num_blocks': 2, 'activation': 'relu', 'batch_size': 128}. Best is trial 1 with value: 0.9965513787447793.
20:35:19 INFO -
===============
| ENSURE DATA |
===============
20:35:19 INFO - Wrote class mapping to data\class_indices.json
20:35:26 INFO - 
=========
| TRAIN |
=========
20:35:26 INFO - Args: {'train_dir': WindowsPath('data/asl_alphabet_train'), 'test_dir': WindowsPath('data/asl_alphabet_test'), 'val_ratio': 0.1, 'subset_per_class': 300, 'epochs': 10, 'batch_size': 64, 'lr': 0.00037691983490414037, 'weight_decay': 2.574845172299871e-05, 'patience': 3, 'model': 'cnn_small', 'aug': False, 'size': 96, 'num_workers': 2, 'class_weights': False, 'dropout': 0.1744236463943966, 'num_blocks': 4, 'activation': 'relu', 'seed': 42, 'use_kaggle': False, 'artifacts_root': WindowsPath('artifacts/asl_runs/hp-tuning')}
20:35:26 INFO - Class distribution (train): {'A': 300, 'B': 300, 'C': 300, 'D': 300, 'E': 300, 'F': 300, 'G': 300, 'H': 300, 'I': 300, 'J': 300, 'K': 300, 'L': 300, 'M': 300, 'N': 300, 'O': 300, 'P': 300, 'Q': 300, 'R': 300, 'S': 300, 'T': 300, 'U': 300, 'V': 300, 'W': 300, 'X': 300, 'Y': 300, 'Z': 300, 'del': 300, 'nothing': 300, 'space': 300}
20:35:26 INFO - Class distribution (val):   {'A': 300, 'B': 300, 'C': 300, 'D': 300, 'E': 300, 'F': 300, 'G': 300, 'H': 300, 'I': 300, 'J': 300, 'K': 300, 'L': 300, 'M': 300, 'N': 300, 'O': 300, 'P': 300, 'Q': 300, 'R': 300, 'S': 300, 'T': 300, 'U': 300, 'V': 300, 'W': 300, 'X': 300, 'Y': 300, 'Z': 300, 'del': 300, 'nothing': 300, 'space': 300}
20:35:27 INFO - Dataset sizes: train=8700, val=8700, test=26
20:35:27 INFO - Model: CNNSmall (blocks=4, act=relu)
20:35:27 INFO - Device: cuda
20:35:27 INFO - Epoch 1/10
20:36:01 INFO - Train: loss=2.5902 acc=0.3266 | Val: loss=1.8985 acc=0.5518 macroF1=0.5157                                                                                                                                 
20:36:02 INFO - New best macro-F1 0.5157 at epoch 1. Checkpoint saved.
20:36:02 INFO - Epoch 2/10
20:36:37 INFO - Train: loss=1.3368 acc=0.6995 | Val: loss=1.0635 acc=0.7601 macroF1=0.7499                                                                                                                                 
20:36:37 INFO - New best macro-F1 0.7499 at epoch 2. Checkpoint saved.
20:36:37 INFO - Epoch 3/10
20:37:11 INFO - Train: loss=0.7051 acc=0.8720 | Val: loss=0.8336 acc=0.7341 macroF1=0.7244                                                                                                                                 
20:37:11 INFO - No improvement (1/3 patience).
20:37:11 INFO - Epoch 4/10
20:37:46 INFO - Train: loss=0.3795 acc=0.9462 | Val: loss=0.3571 acc=0.9328 macroF1=0.9304                                                                                                                                 
20:37:47 INFO - New best macro-F1 0.9304 at epoch 4. Checkpoint saved.
20:37:47 INFO - Epoch 5/10
20:38:22 INFO - Train: loss=0.2261 acc=0.9747 | Val: loss=0.2476 acc=0.9534 macroF1=0.9528                                                                                                                                 
20:38:22 INFO - New best macro-F1 0.9528 at epoch 5. Checkpoint saved.
20:38:22 INFO - Epoch 6/10
20:38:57 INFO - Train: loss=0.1427 acc=0.9859 | Val: loss=0.1677 acc=0.9718 macroF1=0.9719                                                                                                                                 
20:38:57 INFO - New best macro-F1 0.9719 at epoch 6. Checkpoint saved.
20:38:57 INFO - Epoch 7/10
20:39:32 INFO - Train: loss=0.0891 acc=0.9923 | Val: loss=0.1181 acc=0.9730 macroF1=0.9725                                                                                                                                 
20:39:32 INFO - New best macro-F1 0.9725 at epoch 7. Checkpoint saved.
20:39:32 INFO - Epoch 8/10
20:40:07 INFO - Train: loss=0.0575 acc=0.9957 | Val: loss=0.0615 acc=0.9960 macroF1=0.9960                                                                                                                                 
20:40:07 INFO - New best macro-F1 0.9960 at epoch 8. Checkpoint saved.
20:40:07 INFO - Epoch 9/10
20:40:42 INFO - Train: loss=0.0394 acc=0.9986 | Val: loss=0.1090 acc=0.9844 macroF1=0.9843                                                                                                                                 
20:40:42 INFO - No improvement (1/3 patience).
20:40:42 INFO - Epoch 10/10
20:41:17 INFO - Train: loss=0.0387 acc=0.9977 | Val: loss=0.0650 acc=0.9862 macroF1=0.9863                                                                                                                                 
20:41:17 INFO - No improvement (2/3 patience).
20:41:17 INFO - Training completed. Artifacts at: artifacts\asl_runs\hp-tuning\2025-10-27_20-35-26__train-cnn_small_lr0.00037692_b64_bl4_act-relu_dr0.174424_ep10_sub300
[I 2025-10-27 20:41:17,230] Trial 8 finished with value: 0.9959732809801355 and parameters: {'lr': 0.00037691983490414037, 'weight_decay': 2.574845172299871e-05, 'dropout': 0.1744236463943966, 'size': 96, 'subset_per_class': 300, 'num_blocks': 4, 'activation': 'relu', 'batch_size': 64}. Best is trial 1 with value: 0.9965513787447793.
20:41:17 INFO - 
===============
| ENSURE DATA |
===============
20:41:17 INFO - Wrote class mapping to data\class_indices.json
20:41:23 INFO - 
=========
| TRAIN |
=========
20:41:23 INFO - Args: {'train_dir': WindowsPath('data/asl_alphabet_train'), 'test_dir': WindowsPath('data/asl_alphabet_test'), 'val_ratio': 0.1, 'subset_per_class': 300, 'epochs': 10, 'batch_size': 64, 'lr': 0.00012679315916069883, 'weight_decay': 6.35592796806876e-05, 'patience': 3, 'model': 'cnn_small', 'aug': False, 'size': 128, 'num_workers': 2, 'class_weights': False, 'dropout': 0.021628012979652667, 'num_blocks': 3, 'activation': 'relu', 'seed': 42, 'use_kaggle': False, 'artifacts_root': WindowsPath('artifacts/asl_runs/hp-tuning')}
20:41:23 INFO - Class distribution (train): {'A': 300, 'B': 300, 'C': 300, 'D': 300, 'E': 300, 'F': 300, 'G': 300, 'H': 300, 'I': 300, 'J': 300, 'K': 300, 'L': 300, 'M': 300, 'N': 300, 'O': 300, 'P': 300, 'Q': 300, 'R': 300, 'S': 300, 'T': 300, 'U': 300, 'V': 300, 'W': 300, 'X': 300, 'Y': 300, 'Z': 300, 'del': 300, 'nothing': 300, 'space': 300}
20:41:23 INFO - Class distribution (val):   {'A': 300, 'B': 300, 'C': 300, 'D': 300, 'E': 300, 'F': 300, 'G': 300, 'H': 300, 'I': 300, 'J': 300, 'K': 300, 'L': 300, 'M': 300, 'N': 300, 'O': 300, 'P': 300, 'Q': 300, 'R': 300, 'S': 300, 'T': 300, 'U': 300, 'V': 300, 'W': 300, 'X': 300, 'Y': 300, 'Z': 300, 'del': 300, 'nothing': 300, 'space': 300}
20:41:24 INFO - Dataset sizes: train=8700, val=8700, test=26
20:41:24 INFO - Model: CNNSmall (blocks=3, act=relu)
20:41:24 INFO - Device: cuda
20:41:24 INFO - Epoch 1/10
20:42:04 INFO - Train: loss=3.2968 acc=0.0702 | Val: loss=3.1678 acc=0.1084 macroF1=0.0585                                                                                                                                 
20:42:05 INFO - New best macro-F1 0.0585 at epoch 1. Checkpoint saved.
20:42:05 INFO - Epoch 2/10
20:42:45 INFO - Train: loss=3.0679 acc=0.1302 | Val: loss=2.9353 acc=0.1902 macroF1=0.1421                                                                                                                                 
20:42:45 INFO - New best macro-F1 0.1421 at epoch 2. Checkpoint saved.
20:42:45 INFO - Epoch 3/10
20:43:25 INFO - Train: loss=2.8609 acc=0.2325 | Val: loss=2.7293 acc=0.2624 macroF1=0.1973                                                                                                                                 
20:43:26 INFO - New best macro-F1 0.1973 at epoch 3. Checkpoint saved.
20:43:26 INFO - Epoch 4/10
20:44:06 INFO - Train: loss=2.6674 acc=0.3091 | Val: loss=2.5642 acc=0.3280 macroF1=0.2729                                                                                                                                 
20:44:06 INFO - New best macro-F1 0.2729 at epoch 4. Checkpoint saved.
20:44:06 INFO - Epoch 5/10
20:44:47 INFO - Train: loss=2.4872 acc=0.3430 | Val: loss=2.3723 acc=0.3672 macroF1=0.3094                                                                                                                                 
20:44:47 INFO - New best macro-F1 0.3094 at epoch 5. Checkpoint saved.
20:44:47 INFO - Epoch 6/10
20:45:28 INFO - Train: loss=2.3274 acc=0.3985 | Val: loss=2.2243 acc=0.4403 macroF1=0.3901                                                                                                                                 
20:45:28 INFO - New best macro-F1 0.3901 at epoch 6. Checkpoint saved.
20:45:28 INFO - Epoch 7/10
20:46:09 INFO - Train: loss=2.1679 acc=0.4466 | Val: loss=2.1151 acc=0.4115 macroF1=0.3670                                                                                                                                 
20:46:09 INFO - No improvement (1/3 patience).
20:46:09 INFO - Epoch 8/10
20:46:49 INFO - Train: loss=2.0314 acc=0.4903 | Val: loss=1.9591 acc=0.4869 macroF1=0.4335                                                                                                                                 
20:46:49 INFO - New best macro-F1 0.4335 at epoch 8. Checkpoint saved.
20:46:49 INFO - Epoch 9/10
20:47:29 INFO - Train: loss=1.8992 acc=0.5141 | Val: loss=1.8504 acc=0.4914 macroF1=0.4575                                                                                                                                 
20:47:30 INFO - New best macro-F1 0.4575 at epoch 9. Checkpoint saved.
20:47:30 INFO - Epoch 10/10
20:48:10 INFO - Train: loss=1.7825 acc=0.5513 | Val: loss=1.7068 acc=0.5945 macroF1=0.5714                                                                                                                                 
20:48:11 INFO - New best macro-F1 0.5714 at epoch 10. Checkpoint saved.
20:48:11 INFO - Training completed. Artifacts at: artifacts\asl_runs\hp-tuning\2025-10-27_20-41-23__train-cnn_small_lr0.000126793_b64_bl3_act-relu_dr0.021628_ep10_sz128_sub300
[I 2025-10-27 20:48:11,204] Trial 9 finished with value: 0.5713968112901575 and parameters: {'lr': 0.00012679315916069883, 'weight_decay': 6.35592796806876e-05, 'dropout': 0.021628012979652667, 'size': 128, 'subset_per_class': 300, 'num_blocks': 3, 'activation': 'relu', 'batch_size': 64}. Best is trial 1 with value: 0.9965513787447793.
20:48:11 INFO - 
===============
| ENSURE DATA |
===============
20:48:11 INFO - Wrote class mapping to data\class_indices.json
20:48:17 INFO - 
=========
| TRAIN |
=========
20:48:17 INFO - Args: {'train_dir': WindowsPath('data/asl_alphabet_train'), 'test_dir': WindowsPath('data/asl_alphabet_test'), 'val_ratio': 0.1, 'subset_per_class': 300, 'epochs': 10, 'batch_size': 128, 'lr': 0.0029155227984945615, 'weight_decay': 0.0004949466940789813, 'patience': 3, 'model': 'cnn_small', 'aug': False, 'size': 96, 'num_workers': 2, 'class_weights': False, 'dropout': 0.11896481346161383, 'num_blocks': 4, 'activation': 'gelu', 'seed': 42, 'use_kaggle': False, 'artifacts_root': WindowsPath('artifacts/asl_runs/hp-tuning')}
20:48:17 INFO - Class distribution (train): {'A': 300, 'B': 300, 'C': 300, 'D': 300, 'E': 300, 'F': 300, 'G': 300, 'H': 300, 'I': 300, 'J': 300, 'K': 300, 'L': 300, 'M': 300, 'N': 300, 'O': 300, 'P': 300, 'Q': 300, 'R': 300, 'S': 300, 'T': 300, 'U': 300, 'V': 300, 'W': 300, 'X': 300, 'Y': 300, 'Z': 300, 'del': 300, 'nothing': 300, 'space': 300}
20:48:17 INFO - Class distribution (val):   {'A': 300, 'B': 300, 'C': 300, 'D': 300, 'E': 300, 'F': 300, 'G': 300, 'H': 300, 'I': 300, 'J': 300, 'K': 300, 'L': 300, 'M': 300, 'N': 300, 'O': 300, 'P': 300, 'Q': 300, 'R': 300, 'S': 300, 'T': 300, 'U': 300, 'V': 300, 'W': 300, 'X': 300, 'Y': 300, 'Z': 300, 'del': 300, 'nothing': 300, 'space': 300}
20:48:18 INFO - Dataset sizes: train=8700, val=8700, test=26
20:48:18 INFO - Model: CNNSmall (blocks=4, act=gelu)
20:48:18 INFO - Device: cuda
20:48:18 INFO - Epoch 1/10
20:48:53 INFO - Train: loss=2.3603 acc=0.3090 | Val: loss=1.7123 acc=0.4522 macroF1=0.4174                                                                                                                                 
20:48:54 INFO - New best macro-F1 0.4174 at epoch 1. Checkpoint saved.
20:48:54 INFO - Epoch 2/10
20:49:29 INFO - Train: loss=0.7975 acc=0.7710 | Val: loss=0.4732 acc=0.8840 macroF1=0.8834                                                                                                                                 
20:49:29 INFO - New best macro-F1 0.8834 at epoch 2. Checkpoint saved.
20:49:29 INFO - Epoch 3/10
20:50:04 INFO - Train: loss=0.3024 acc=0.9237 | Val: loss=0.4002 acc=0.8759 macroF1=0.8749                                                                                                                                 
20:50:04 INFO - No improvement (1/3 patience).
20:50:04 INFO - Epoch 4/10
20:50:39 INFO - Train: loss=0.1505 acc=0.9675 | Val: loss=0.5629 acc=0.8228 macroF1=0.8209                                                                                                                                 
20:50:39 INFO - No improvement (2/3 patience).
20:50:39 INFO - Epoch 5/10
20:51:14 INFO - Train: loss=0.1251 acc=0.9708 | Val: loss=0.3901 acc=0.8800 macroF1=0.8787                                                                                                                                 
20:51:14 INFO - No improvement (3/3 patience).
20:51:14 INFO - Early stopping triggered.
20:51:14 INFO - Training completed. Artifacts at: artifacts\asl_runs\hp-tuning\2025-10-27_20-48-17__train-cnn_small_lr0.00291552_b128_bl4_act-gelu_dr0.118965_ep10_sub300
[I 2025-10-27 20:51:14,919] Trial 10 finished with value: 0.8833543987867212 and parameters: {'lr': 0.0029155227984945615, 'weight_decay': 0.0004949466940789813, 'dropout': 0.11896481346161383, 'size': 96, 'subset_per_class': 300, 'num_blocks': 4, 'activation': 'gelu', 'batch_size': 128}. Best is trial 1 with value: 0.9965513787447793.
20:51:14 INFO - 
===============
| ENSURE DATA |
===============
20:51:14 INFO - Wrote class mapping to data\class_indices.json
20:51:21 INFO - 
=========
| TRAIN |
=========
20:51:21 INFO - Args: {'train_dir': WindowsPath('data/asl_alphabet_train'), 'test_dir': WindowsPath('data/asl_alphabet_test'), 'val_ratio': 0.1, 'subset_per_class': 300, 'epochs': 10, 'batch_size': 64, 'lr': 0.001602065127575807, 'weight_decay': 6.928442366595536e-06, 'patience': 3, 'model': 'cnn_small', 'aug': False, 'size': 96, 'num_workers': 2, 'class_weights': False, 'dropout': 0.17138045094535131, 'num_blocks': 4, 'activation': 'relu', 'seed': 42, 'use_kaggle': False, 'artifacts_root': WindowsPath('artifacts/asl_runs/hp-tuning')}
20:51:21 INFO - Class distribution (train): {'A': 300, 'B': 300, 'C': 300, 'D': 300, 'E': 300, 'F': 300, 'G': 300, 'H': 300, 'I': 300, 'J': 300, 'K': 300, 'L': 300, 'M': 300, 'N': 300, 'O': 300, 'P': 300, 'Q': 300, 'R': 300, 'S': 300, 'T': 300, 'U': 300, 'V': 300, 'W': 300, 'X': 300, 'Y': 300, 'Z': 300, 'del': 300, 'nothing': 300, 'space': 300}
20:51:21 INFO - Class distribution (val):   {'A': 300, 'B': 300, 'C': 300, 'D': 300, 'E': 300, 'F': 300, 'G': 300, 'H': 300, 'I': 300, 'J': 300, 'K': 300, 'L': 300, 'M': 300, 'N': 300, 'O': 300, 'P': 300, 'Q': 300, 'R': 300, 'S': 300, 'T': 300, 'U': 300, 'V': 300, 'W': 300, 'X': 300, 'Y': 300, 'Z': 300, 'del': 300, 'nothing': 300, 'space': 300}
20:51:22 INFO - Dataset sizes: train=8700, val=8700, test=26
20:51:22 INFO - Model: CNNSmall (blocks=4, act=relu)
20:51:22 INFO - Device: cuda
20:51:22 INFO - Epoch 1/10
20:51:57 INFO - Train: loss=2.1667 acc=0.3687 | Val: loss=1.4177 acc=0.5616 macroF1=0.5212                                                                                                                                 
20:51:57 INFO - New best macro-F1 0.5212 at epoch 1. Checkpoint saved.
20:51:57 INFO - Epoch 2/10
20:52:32 INFO - Train: loss=0.6886 acc=0.8097 | Val: loss=0.7011 acc=0.7637 macroF1=0.7513                                                                                                                                 
20:52:32 INFO - New best macro-F1 0.7513 at epoch 2. Checkpoint saved.
20:52:32 INFO - Epoch 3/10
20:53:07 INFO - Train: loss=0.2795 acc=0.9302 | Val: loss=0.3838 acc=0.8833 macroF1=0.8839                                                                                                                                 
20:53:07 INFO - New best macro-F1 0.8839 at epoch 3. Checkpoint saved.
20:53:07 INFO - Epoch 4/10
20:53:42 INFO - Train: loss=0.1410 acc=0.9686 | Val: loss=0.1793 acc=0.9546 macroF1=0.9544                                                                                                                                 
20:53:43 INFO - New best macro-F1 0.9544 at epoch 4. Checkpoint saved.
20:53:43 INFO - Epoch 5/10
20:54:18 INFO - Train: loss=0.0848 acc=0.9818 | Val: loss=0.0678 acc=0.9825 macroF1=0.9826                                                                                                                                 
20:54:18 INFO - New best macro-F1 0.9826 at epoch 5. Checkpoint saved.
20:54:18 INFO - Epoch 6/10
20:54:53 INFO - Train: loss=0.0608 acc=0.9875 | Val: loss=0.0613 acc=0.9795 macroF1=0.9796                                                                                                                                 
20:54:53 INFO - No improvement (1/3 patience).
20:54:53 INFO - Epoch 7/10
20:55:28 INFO - Train: loss=0.0316 acc=0.9951 | Val: loss=0.0649 acc=0.9778 macroF1=0.9779                                                                                                                                 
20:55:28 INFO - No improvement (2/3 patience).
20:55:28 INFO - Epoch 8/10
20:56:02 INFO - Train: loss=0.0313 acc=0.9941 | Val: loss=0.0628 acc=0.9789 macroF1=0.9789                                                                                                                                 
20:56:02 INFO - No improvement (3/3 patience).
20:56:02 INFO - Early stopping triggered.
20:56:02 INFO - Training completed. Artifacts at: artifacts\asl_runs\hp-tuning\2025-10-27_20-51-21__train-cnn_small_lr0.00160207_b64_bl4_act-relu_dr0.17138_ep10_sub300
[I 2025-10-27 20:56:02,753] Trial 11 finished with value: 0.9826199963979897 and parameters: {'lr': 0.001602065127575807, 'weight_decay': 6.928442366595536e-06, 'dropout': 0.17138045094535131, 'size': 96, 'subset_per_class': 300, 'num_blocks': 4, 'activation': 'relu', 'batch_size': 64}. Best is trial 1 with value: 0.9965513787447793.
20:56:02 INFO - 
===============
| ENSURE DATA |
===============
20:56:02 INFO - Wrote class mapping to data\class_indices.json
20:56:09 INFO - 
=========
| TRAIN |
=========
20:56:09 INFO - Args: {'train_dir': WindowsPath('data/asl_alphabet_train'), 'test_dir': WindowsPath('data/asl_alphabet_test'), 'val_ratio': 0.1, 'subset_per_class': 300, 'epochs': 10, 'batch_size': 128, 'lr': 0.0007860284807278831, 'weight_decay': 2.2857067262832506e-05, 'patience': 3, 'model': 'cnn_small', 'aug': False, 'size': 96, 'num_workers': 2, 'class_weights': False, 'dropout': 0.27705149963645503, 'num_blocks': 4, 'activation': 'relu', 'seed': 42, 'use_kaggle': False, 'artifacts_root': WindowsPath('artifacts/asl_runs/hp-tuning')}
20:56:09 INFO - Class distribution (train): {'A': 300, 'B': 300, 'C': 300, 'D': 300, 'E': 300, 'F': 300, 'G': 300, 'H': 300, 'I': 300, 'J': 300, 'K': 300, 'L': 300, 'M': 300, 'N': 300, 'O': 300, 'P': 300, 'Q': 300, 'R': 300, 'S': 300, 'T': 300, 'U': 300, 'V': 300, 'W': 300, 'X': 300, 'Y': 300, 'Z': 300, 'del': 300, 'nothing': 300, 'space': 300}
20:56:09 INFO - Class distribution (val):   {'A': 300, 'B': 300, 'C': 300, 'D': 300, 'E': 300, 'F': 300, 'G': 300, 'H': 300, 'I': 300, 'J': 300, 'K': 300, 'L': 300, 'M': 300, 'N': 300, 'O': 300, 'P': 300, 'Q': 300, 'R': 300, 'S': 300, 'T': 300, 'U': 300, 'V': 300, 'W': 300, 'X': 300, 'Y': 300, 'Z': 300, 'del': 300, 'nothing': 300, 'space': 300}
20:56:10 INFO - Dataset sizes: train=8700, val=8700, test=26
20:56:10 INFO - Model: CNNSmall (blocks=4, act=relu)
20:56:10 INFO - Device: cuda
20:56:10 INFO - Epoch 1/10
20:56:45 INFO - Train: loss=2.5752 acc=0.3098 | Val: loss=1.9253 acc=0.5531 macroF1=0.5305                                                                                                                                 
20:56:46 INFO - New best macro-F1 0.5305 at epoch 1. Checkpoint saved.
20:56:46 INFO - Epoch 2/10
20:57:21 INFO - Train: loss=1.2890 acc=0.6808 | Val: loss=1.3217 acc=0.5771 macroF1=0.5373                                                                                                                                 
20:57:21 INFO - New best macro-F1 0.5373 at epoch 2. Checkpoint saved.
20:57:21 INFO - Epoch 3/10
20:57:57 INFO - Train: loss=0.6784 acc=0.8515 | Val: loss=0.7009 acc=0.7705 macroF1=0.7781                                                                                                                                 
20:57:57 INFO - New best macro-F1 0.7781 at epoch 3. Checkpoint saved.
20:57:57 INFO - Epoch 4/10
20:58:32 INFO - Train: loss=0.3660 acc=0.9343 | Val: loss=0.5006 acc=0.8555 macroF1=0.8471                                                                                                                                 
20:58:32 INFO - New best macro-F1 0.8471 at epoch 4. Checkpoint saved.
20:58:32 INFO - Epoch 5/10
20:59:07 INFO - Train: loss=0.2044 acc=0.9725 | Val: loss=0.2665 acc=0.9224 macroF1=0.9208                                                                                                                                 
20:59:08 INFO - New best macro-F1 0.9208 at epoch 5. Checkpoint saved.
20:59:08 INFO - Epoch 6/10
20:59:43 INFO - Train: loss=0.1204 acc=0.9874 | Val: loss=0.2485 acc=0.9369 macroF1=0.9380                                                                                                                                 
20:59:44 INFO - New best macro-F1 0.9380 at epoch 6. Checkpoint saved.
20:59:44 INFO - Epoch 7/10
21:00:19 INFO - Train: loss=0.0777 acc=0.9929 | Val: loss=0.1198 acc=0.9729 macroF1=0.9729                                                                                                                                 
21:00:19 INFO - New best macro-F1 0.9729 at epoch 7. Checkpoint saved.
21:00:19 INFO - Epoch 8/10
21:00:54 INFO - Train: loss=0.0547 acc=0.9952 | Val: loss=0.1306 acc=0.9685 macroF1=0.9684                                                                                                                                 
21:00:54 INFO - No improvement (1/3 patience).
21:00:54 INFO - Epoch 9/10
21:01:30 INFO - Train: loss=0.0354 acc=0.9983 | Val: loss=0.0661 acc=0.9891 macroF1=0.9891                                                                                                                                 
21:01:30 INFO - New best macro-F1 0.9891 at epoch 9. Checkpoint saved.
21:01:30 INFO - Epoch 10/10
21:02:05 INFO - Train: loss=0.0258 acc=0.9984 | Val: loss=0.1051 acc=0.9664 macroF1=0.9663                                                                                                                                 
21:02:05 INFO - No improvement (1/3 patience).
21:02:05 INFO - Training completed. Artifacts at: artifacts\asl_runs\hp-tuning\2025-10-27_20-56-09__train-cnn_small_lr0.000786028_b128_bl4_act-relu_dr0.277051_ep10_sub300
[I 2025-10-27 21:02:05,621] Trial 12 finished with value: 0.9890655234358022 and parameters: {'lr': 0.0007860284807278831, 'weight_decay': 2.2857067262832506e-05, 'dropout': 0.27705149963645503, 'size': 96, 'subset_per_class': 300, 'num_blocks': 4, 'activation': 'relu', 'batch_size': 128}. Best is trial 1 with value: 0.9965513787447793.
21:02:05 INFO - 
===============
| ENSURE DATA |
===============
21:02:05 INFO - Wrote class mapping to data\class_indices.json
21:02:12 INFO - 
=========
| TRAIN |
=========
21:02:12 INFO - Args: {'train_dir': WindowsPath('data/asl_alphabet_train'), 'test_dir': WindowsPath('data/asl_alphabet_test'), 'val_ratio': 0.1, 'subset_per_class': 300, 'epochs': 10, 'batch_size': 128, 'lr': 0.0029715807088735, 'weight_decay': 4.0805928221545005e-06, 'patience': 3, 'model': 'cnn_small', 'aug': False, 'size': 96, 'num_workers': 2, 'class_weights': False, 'dropout': 0.16515216209912814, 'num_blocks': 4, 'activation': 'relu', 'seed': 42, 'use_kaggle': False, 'artifacts_root': WindowsPath('artifacts/asl_runs/hp-tuning')}
21:02:12 INFO - Class distribution (train): {'A': 300, 'B': 300, 'C': 300, 'D': 300, 'E': 300, 'F': 300, 'G': 300, 'H': 300, 'I': 300, 'J': 300, 'K': 300, 'L': 300, 'M': 300, 'N': 300, 'O': 300, 'P': 300, 'Q': 300, 'R': 300, 'S': 300, 'T': 300, 'U': 300, 'V': 300, 'W': 300, 'X': 300, 'Y': 300, 'Z': 300, 'del': 300, 'nothing': 300, 'space': 300}
21:02:12 INFO - Class distribution (val):   {'A': 300, 'B': 300, 'C': 300, 'D': 300, 'E': 300, 'F': 300, 'G': 300, 'H': 300, 'I': 300, 'J': 300, 'K': 300, 'L': 300, 'M': 300, 'N': 300, 'O': 300, 'P': 300, 'Q': 300, 'R': 300, 'S': 300, 'T': 300, 'U': 300, 'V': 300, 'W': 300, 'X': 300, 'Y': 300, 'Z': 300, 'del': 300, 'nothing': 300, 'space': 300}
21:02:13 INFO - Dataset sizes: train=8700, val=8700, test=26
21:02:13 INFO - Model: CNNSmall (blocks=4, act=relu)
21:02:13 INFO - Device: cuda
21:02:13 INFO - Epoch 1/10
21:02:48 INFO - Train: loss=2.3874 acc=0.2951 | Val: loss=1.5311 acc=0.4869 macroF1=0.4413                                                                                                                                 
21:02:48 INFO - New best macro-F1 0.4413 at epoch 1. Checkpoint saved.
21:02:48 INFO - Epoch 2/10
21:03:24 INFO - Train: loss=0.9271 acc=0.7272 | Val: loss=0.9607 acc=0.6654 macroF1=0.6633                                                                                                                                 
21:03:24 INFO - New best macro-F1 0.6633 at epoch 2. Checkpoint saved.
21:03:24 INFO - Epoch 3/10
21:03:59 INFO - Train: loss=0.3773 acc=0.8969 | Val: loss=0.2783 acc=0.9110 macroF1=0.9095                                                                                                                                 
21:04:00 INFO - New best macro-F1 0.9095 at epoch 3. Checkpoint saved.
21:04:00 INFO - Epoch 4/10
21:04:35 INFO - Train: loss=0.1763 acc=0.9593 | Val: loss=0.5953 acc=0.8180 macroF1=0.8231                                                                                                                                 
21:04:35 INFO - No improvement (1/3 patience).
21:04:35 INFO - Epoch 5/10
21:05:11 INFO - Train: loss=0.1177 acc=0.9717 | Val: loss=0.1598 acc=0.9598 macroF1=0.9599                                                                                                                                 
21:05:12 INFO - New best macro-F1 0.9599 at epoch 5. Checkpoint saved.
21:05:12 INFO - Epoch 6/10
21:05:47 INFO - Train: loss=0.0697 acc=0.9856 | Val: loss=0.2088 acc=0.9297 macroF1=0.9298                                                                                                                                 
21:05:47 INFO - No improvement (1/3 patience).
21:05:47 INFO - Epoch 7/10
21:06:22 INFO - Train: loss=0.0432 acc=0.9911 | Val: loss=0.0670 acc=0.9820 macroF1=0.9820                                                                                                                                 
21:06:23 INFO - New best macro-F1 0.9820 at epoch 7. Checkpoint saved.
21:06:23 INFO - Epoch 8/10
21:06:58 INFO - Train: loss=0.0312 acc=0.9936 | Val: loss=0.2542 acc=0.9287 macroF1=0.9293                                                                                                                                 
21:06:58 INFO - No improvement (1/3 patience).
21:06:58 INFO - Epoch 9/10
21:07:32 INFO - Train: loss=0.0279 acc=0.9937 | Val: loss=0.0816 acc=0.9762 macroF1=0.9759                                                                                                                                 
21:07:32 INFO - No improvement (2/3 patience).
21:07:32 INFO - Epoch 10/10
21:08:06 INFO - Train: loss=0.0262 acc=0.9946 | Val: loss=0.0571 acc=0.9836 macroF1=0.9836                                                                                                                                 
21:08:06 INFO - New best macro-F1 0.9836 at epoch 10. Checkpoint saved.
21:08:06 INFO - Training completed. Artifacts at: artifacts\asl_runs\hp-tuning\2025-10-27_21-02-12__train-cnn_small_lr0.00297158_b128_bl4_act-relu_dr0.165152_ep10_sub300
[I 2025-10-27 21:08:06,771] Trial 13 finished with value: 0.983649169388691 and parameters: {'lr': 0.0029715807088735, 'weight_decay': 4.0805928221545005e-06, 'dropout': 0.16515216209912814, 'size': 96, 'subset_per_class': 300, 'num_blocks': 4, 'activation': 'relu', 'batch_size': 128}. Best is trial 1 with value: 0.9965513787447793.
21:08:06 INFO -
===============
| ENSURE DATA |
===============
21:08:06 INFO - Wrote class mapping to data\class_indices.json
21:08:13 INFO - 
=========
| TRAIN |
=========
21:08:13 INFO - Args: {'train_dir': WindowsPath('data/asl_alphabet_train'), 'test_dir': WindowsPath('data/asl_alphabet_test'), 'val_ratio': 0.1, 'subset_per_class': 300, 'epochs': 10, 'batch_size': 64, 'lr': 0.0016001842538945564, 'weight_decay': 3.982689984050929e-05, 'patience': 3, 'model': 'cnn_small', 'aug': False, 'size': 96, 'num_workers': 2, 'class_weights': False, 'dropout': 0.13684210745701567, 'num_blocks': 4, 'activation': 'relu', 'seed': 42, 'use_kaggle': False, 'artifacts_root': WindowsPath('artifacts/asl_runs/hp-tuning')}
21:08:13 INFO - Class distribution (train): {'A': 300, 'B': 300, 'C': 300, 'D': 300, 'E': 300, 'F': 300, 'G': 300, 'H': 300, 'I': 300, 'J': 300, 'K': 300, 'L': 300, 'M': 300, 'N': 300, 'O': 300, 'P': 300, 'Q': 300, 'R': 300, 'S': 300, 'T': 300, 'U': 300, 'V': 300, 'W': 300, 'X': 300, 'Y': 300, 'Z': 300, 'del': 300, 'nothing': 300, 'space': 300}
21:08:13 INFO - Class distribution (val):   {'A': 300, 'B': 300, 'C': 300, 'D': 300, 'E': 300, 'F': 300, 'G': 300, 'H': 300, 'I': 300, 'J': 300, 'K': 300, 'L': 300, 'M': 300, 'N': 300, 'O': 300, 'P': 300, 'Q': 300, 'R': 300, 'S': 300, 'T': 300, 'U': 300, 'V': 300, 'W': 300, 'X': 300, 'Y': 300, 'Z': 300, 'del': 300, 'nothing': 300, 'space': 300}
21:08:14 INFO - Dataset sizes: train=8700, val=8700, test=26
21:08:14 INFO - Model: CNNSmall (blocks=4, act=relu)
21:08:14 INFO - Device: cuda
21:08:14 INFO - Epoch 1/10
21:08:47 INFO - Train: loss=2.1938 acc=0.3591 | Val: loss=1.4707 acc=0.4993 macroF1=0.4814                                                                                                                                 
21:08:48 INFO - New best macro-F1 0.4814 at epoch 1. Checkpoint saved.
21:08:48 INFO - Epoch 2/10
21:09:22 INFO - Train: loss=0.7250 acc=0.7933 | Val: loss=0.6007 acc=0.7931 macroF1=0.7807                                                                                                                                 
21:09:22 INFO - New best macro-F1 0.7807 at epoch 2. Checkpoint saved.
21:09:22 INFO - Epoch 3/10
21:10:01 INFO - Train: loss=0.2958 acc=0.9244 | Val: loss=0.2857 acc=0.9232 macroF1=0.9223                                                                                                                                 
21:10:02 INFO - New best macro-F1 0.9223 at epoch 3. Checkpoint saved.
21:10:02 INFO - Epoch 4/10
21:10:40 INFO - Train: loss=0.1465 acc=0.9671 | Val: loss=0.1703 acc=0.9541 macroF1=0.9542                                                                                                                                 
21:10:41 INFO - New best macro-F1 0.9542 at epoch 4. Checkpoint saved.
21:10:41 INFO - Epoch 5/10
21:11:21 INFO - Train: loss=0.0875 acc=0.9815 | Val: loss=0.3437 acc=0.8813 macroF1=0.8773                                                                                                                                 
21:11:21 INFO - No improvement (1/3 patience).
21:11:21 INFO - Epoch 6/10
21:12:00 INFO - Train: loss=0.0649 acc=0.9868 | Val: loss=0.1069 acc=0.9736 macroF1=0.9736                                                                                                                                 
21:12:01 INFO - New best macro-F1 0.9736 at epoch 6. Checkpoint saved.
21:12:01 INFO - Epoch 7/10
21:12:39 INFO - Train: loss=0.0353 acc=0.9941 | Val: loss=0.0423 acc=0.9876 macroF1=0.9876                                                                                                                                 
21:12:39 INFO - New best macro-F1 0.9876 at epoch 7. Checkpoint saved.
21:12:39 INFO - Epoch 8/10
21:13:19 INFO - Train: loss=0.0158 acc=0.9977 | Val: loss=0.0912 acc=0.9670 macroF1=0.9675                                                                                                                                 
21:13:19 INFO - No improvement (1/3 patience).
21:13:19 INFO - Epoch 9/10
21:13:59 INFO - Train: loss=0.0434 acc=0.9906 | Val: loss=0.2181 acc=0.9325 macroF1=0.9311                                                                                                                                 
21:13:59 INFO - No improvement (2/3 patience).
21:13:59 INFO - Epoch 10/10
21:14:39 INFO - Train: loss=0.0669 acc=0.9826 | Val: loss=0.0537 acc=0.9837 macroF1=0.9836                                                                                                                                 
21:14:39 INFO - No improvement (3/3 patience).
21:14:39 INFO - Early stopping triggered.
21:14:39 INFO - Training completed. Artifacts at: artifacts\asl_runs\hp-tuning\2025-10-27_21-08-13__train-cnn_small_lr0.00160018_b64_bl4_act-relu_dr0.136842_ep10_sub300
[I 2025-10-27 21:14:39,024] Trial 14 finished with value: 0.9876165479849243 and parameters: {'lr': 0.0016001842538945564, 'weight_decay': 3.982689984050929e-05, 'dropout': 0.13684210745701567, 'size': 96, 'subset_per_class': 300, 'num_blocks': 4, 'activation': 'relu', 'batch_size': 64}. Best is trial 1 with value: 0.9965513787447793.
21:14:39 INFO - 
===============
| ENSURE DATA |
===============
21:14:39 INFO - Wrote class mapping to data\class_indices.json
21:14:50 INFO - 
=========
| TRAIN |
=========
21:14:50 INFO - Args: {'train_dir': WindowsPath('data/asl_alphabet_train'), 'test_dir': WindowsPath('data/asl_alphabet_test'), 'val_ratio': 0.1, 'subset_per_class': 300, 'epochs': 10, 'batch_size': 128, 'lr': 0.00022082199650557042, 'weight_decay': 3.4545190173925964e-06, 'patience': 3, 'model': 'cnn_small', 'aug': False, 'size': 96, 'num_workers': 2, 'class_weights': False, 'dropout': 0.06061602293367746, 'num_blocks': 4, 'activation': 'relu', 'seed': 42, 'use_kaggle': False, 'artifacts_root': WindowsPath('artifacts/asl_runs/hp-tuning')}
21:14:50 INFO - Class distribution (train): {'A': 300, 'B': 300, 'C': 300, 'D': 300, 'E': 300, 'F': 300, 'G': 300, 'H': 300, 'I': 300, 'J': 300, 'K': 300, 'L': 300, 'M': 300, 'N': 300, 'O': 300, 'P': 300, 'Q': 300, 'R': 300, 'S': 300, 'T': 300, 'U': 300, 'V': 300, 'W': 300, 'X': 300, 'Y': 300, 'Z': 300, 'del': 300, 'nothing': 300, 'space': 300}
21:14:50 INFO - Class distribution (val):   {'A': 300, 'B': 300, 'C': 300, 'D': 300, 'E': 300, 'F': 300, 'G': 300, 'H': 300, 'I': 300, 'J': 300, 'K': 300, 'L': 300, 'M': 300, 'N': 300, 'O': 300, 'P': 300, 'Q': 300, 'R': 300, 'S': 300, 'T': 300, 'U': 300, 'V': 300, 'W': 300, 'X': 300, 'Y': 300, 'Z': 300, 'del': 300, 'nothing': 300, 'space': 300}
21:14:51 INFO - Dataset sizes: train=8700, val=8700, test=26
21:14:51 INFO - Model: CNNSmall (blocks=4, act=relu)
21:14:51 INFO - Device: cuda
21:14:51 INFO - Epoch 1/10
21:15:31 INFO - Train: loss=3.0241 acc=0.2093 | Val: loss=2.5763 acc=0.4077 macroF1=0.3644                                                                                                                                 
21:15:32 INFO - New best macro-F1 0.3644 at epoch 1. Checkpoint saved.
21:15:32 INFO - Epoch 2/10
21:16:11 INFO - Train: loss=2.2265 acc=0.5098 | Val: loss=1.8713 acc=0.5799 macroF1=0.5300                                                                                                                                 
21:16:11 INFO - New best macro-F1 0.5300 at epoch 2. Checkpoint saved.
21:16:11 INFO - Epoch 3/10
21:16:51 INFO - Train: loss=1.6304 acc=0.6607 | Val: loss=1.5409 acc=0.5677 macroF1=0.5411                                                                                                                                 
21:16:52 INFO - New best macro-F1 0.5411 at epoch 3. Checkpoint saved.
21:16:52 INFO - Epoch 4/10
21:17:31 INFO - Train: loss=1.2099 acc=0.7720 | Val: loss=1.1613 acc=0.7722 macroF1=0.7700                                                                                                                                 
21:17:31 INFO - New best macro-F1 0.7700 at epoch 4. Checkpoint saved.
21:17:31 INFO - Epoch 5/10
21:18:11 INFO - Train: loss=0.8984 acc=0.8491 | Val: loss=0.8481 acc=0.8346 macroF1=0.8270                                                                                                                                 
21:18:12 INFO - New best macro-F1 0.8270 at epoch 5. Checkpoint saved.
21:18:12 INFO - Epoch 6/10
21:18:51 INFO - Train: loss=0.6699 acc=0.9103 | Val: loss=0.7157 acc=0.8437 macroF1=0.8428                                                                                                                                 
21:18:52 INFO - New best macro-F1 0.8428 at epoch 6. Checkpoint saved.
21:18:52 INFO - Epoch 7/10
21:19:31 INFO - Train: loss=0.5007 acc=0.9413 | Val: loss=0.5659 acc=0.8762 macroF1=0.8720                                                                                                                                 
21:19:32 INFO - New best macro-F1 0.8720 at epoch 7. Checkpoint saved.
21:19:32 INFO - Epoch 8/10
21:20:11 INFO - Train: loss=0.3695 acc=0.9703 | Val: loss=0.4544 acc=0.9233 macroF1=0.9210                                                                                                                                 
21:20:12 INFO - New best macro-F1 0.9210 at epoch 8. Checkpoint saved.
21:20:12 INFO - Epoch 9/10
21:20:52 INFO - Train: loss=0.2869 acc=0.9768 | Val: loss=0.3667 acc=0.9510 macroF1=0.9509                                                                                                                                 
21:20:52 INFO - New best macro-F1 0.9509 at epoch 9. Checkpoint saved.
21:20:52 INFO - Epoch 10/10
21:21:32 INFO - Train: loss=0.2142 acc=0.9872 | Val: loss=0.2525 acc=0.9662 macroF1=0.9659                                                                                                                                 
21:21:32 INFO - New best macro-F1 0.9659 at epoch 10. Checkpoint saved.
21:21:32 INFO - Training completed. Artifacts at: artifacts\asl_runs\hp-tuning\2025-10-27_21-14-50__train-cnn_small_lr0.000220822_b128_bl4_act-relu_dr0.060616_ep10_sub300
[I 2025-10-27 21:21:32,979] Trial 15 finished with value: 0.9659074600030251 and parameters: {'lr': 0.00022082199650557042, 'weight_decay': 3.4545190173925964e-06, 'dropout': 0.06061602293367746, 'size': 96, 'subset_per_class': 300, 'num_blocks': 4, 'activation': 'relu', 'batch_size': 128}. Best is trial 1 with value: 0.9965513787447793.
21:21:32 INFO - 
===============
| ENSURE DATA |
===============
21:21:32 INFO - Wrote class mapping to data\class_indices.json
21:21:43 INFO - 
=========
| TRAIN |
=========
21:21:43 INFO - Args: {'train_dir': WindowsPath('data/asl_alphabet_train'), 'test_dir': WindowsPath('data/asl_alphabet_test'), 'val_ratio': 0.1, 'subset_per_class': 300, 'epochs': 10, 'batch_size': 64, 'lr': 0.0006274665991551688, 'weight_decay': 1.3941097789426736e-05, 'patience': 3, 'model': 'cnn_small', 'aug': False, 'size': 128, 'num_workers': 2, 'class_weights': False, 'dropout': 0.2994366043352955, 'num_blocks': 2, 'activation': 'relu', 'seed': 42, 'use_kaggle': False, 'artifacts_root': WindowsPath('artifacts/asl_runs/hp-tuning')}
21:21:43 INFO - Class distribution (train): {'A': 300, 'B': 300, 'C': 300, 'D': 300, 'E': 300, 'F': 300, 'G': 300, 'H': 300, 'I': 300, 'J': 300, 'K': 300, 'L': 300, 'M': 300, 'N': 300, 'O': 300, 'P': 300, 'Q': 300, 'R': 300, 'S': 300, 'T': 300, 'U': 300, 'V': 300, 'W': 300, 'X': 300, 'Y': 300, 'Z': 300, 'del': 300, 'nothing': 300, 'space': 300}
21:21:43 INFO - Class distribution (val):   {'A': 300, 'B': 300, 'C': 300, 'D': 300, 'E': 300, 'F': 300, 'G': 300, 'H': 300, 'I': 300, 'J': 300, 'K': 300, 'L': 300, 'M': 300, 'N': 300, 'O': 300, 'P': 300, 'Q': 300, 'R': 300, 'S': 300, 'T': 300, 'U': 300, 'V': 300, 'W': 300, 'X': 300, 'Y': 300, 'Z': 300, 'del': 300, 'nothing': 300, 'space': 300}
21:21:45 INFO - Dataset sizes: train=8700, val=8700, test=26
21:21:45 INFO - Model: CNNSmall (blocks=2, act=relu)
21:21:45 INFO - Device: cuda
21:21:45 INFO - Epoch 1/10
21:22:26 INFO - Train: loss=3.2874 acc=0.0549 | Val: loss=3.1497 acc=0.0697 macroF1=0.0306                                                                                                                                 
21:22:27 INFO - New best macro-F1 0.0306 at epoch 1. Checkpoint saved.
21:22:27 INFO - Epoch 2/10
21:23:07 INFO - Train: loss=3.0490 acc=0.0964 | Val: loss=2.9289 acc=0.1370 macroF1=0.0749                                                                                                                                 
21:23:08 INFO - New best macro-F1 0.0749 at epoch 2. Checkpoint saved.
21:23:08 INFO - Epoch 3/10
21:23:48 INFO - Train: loss=2.8484 acc=0.1597 | Val: loss=2.7187 acc=0.2053 macroF1=0.1424                                                                                                                                 
21:23:49 INFO - New best macro-F1 0.1424 at epoch 3. Checkpoint saved.
21:23:49 INFO - Epoch 4/10
21:24:29 INFO - Train: loss=2.6844 acc=0.1995 | Val: loss=2.5672 acc=0.2203 macroF1=0.1734                                                                                                                                 
21:24:29 INFO - New best macro-F1 0.1734 at epoch 4. Checkpoint saved.
21:24:29 INFO - Epoch 5/10
21:25:11 INFO - Train: loss=2.5461 acc=0.2187 | Val: loss=2.4085 acc=0.2515 macroF1=0.1836                                                                                                                                 
21:25:11 INFO - New best macro-F1 0.1836 at epoch 5. Checkpoint saved.
21:25:11 INFO - Epoch 6/10
21:25:51 INFO - Train: loss=2.4256 acc=0.2647 | Val: loss=2.4882 acc=0.2578 macroF1=0.2165                                                                                                                                 
21:25:52 INFO - New best macro-F1 0.2165 at epoch 6. Checkpoint saved.
21:25:52 INFO - Epoch 7/10
21:26:31 INFO - Train: loss=2.3215 acc=0.2845 | Val: loss=2.2158 acc=0.3359 macroF1=0.2960                                                                                                                                 
21:26:32 INFO - New best macro-F1 0.2960 at epoch 7. Checkpoint saved.
21:26:32 INFO - Epoch 8/10
21:27:12 INFO - Train: loss=2.2522 acc=0.3039 | Val: loss=2.1646 acc=0.3598 macroF1=0.3208                                                                                                                                 
21:27:12 INFO - New best macro-F1 0.3208 at epoch 8. Checkpoint saved.
21:27:12 INFO - Epoch 9/10
21:27:52 INFO - Train: loss=2.1652 acc=0.3310 | Val: loss=2.1345 acc=0.3952 macroF1=0.3543                                                                                                                                 
21:27:53 INFO - New best macro-F1 0.3543 at epoch 9. Checkpoint saved.
21:27:53 INFO - Epoch 10/10
21:28:32 INFO - Train: loss=2.1013 acc=0.3494 | Val: loss=1.9798 acc=0.3939 macroF1=0.3729                                                                                                                                 
21:28:33 INFO - New best macro-F1 0.3729 at epoch 10. Checkpoint saved.
21:28:33 INFO - Training completed. Artifacts at: artifacts\asl_runs\hp-tuning\2025-10-27_21-21-43__train-cnn_small_lr0.000627467_b64_bl2_act-relu_dr0.299437_ep10_sz128_sub300
[I 2025-10-27 21:28:33,590] Trial 16 finished with value: 0.37286813710084477 and parameters: {'lr': 0.0006274665991551688, 'weight_decay': 1.3941097789426736e-05, 'dropout': 0.2994366043352955, 'size': 128, 'subset_per_class': 300, 'num_blocks': 2, 'activation': 'relu', 'batch_size': 64}. Best is trial 1 with value: 0.9965513787447793.
21:28:33 INFO - 
===============
| ENSURE DATA |
===============
21:28:33 INFO - Wrote class mapping to data\class_indices.json
21:28:44 INFO - 
=========
| TRAIN |
=========
21:28:44 INFO - Args: {'train_dir': WindowsPath('data/asl_alphabet_train'), 'test_dir': WindowsPath('data/asl_alphabet_test'), 'val_ratio': 0.1, 'subset_per_class': 300, 'epochs': 10, 'batch_size': 64, 'lr': 0.0010764408093705184, 'weight_decay': 0.00013008367472836841, 'patience': 3, 'model': 'cnn_small', 'aug': False, 'size': 96, 'num_workers': 2, 'class_weights': False, 'dropout': 0.19735802797784704, 'num_blocks': 4, 'activation': 'relu', 'seed': 42, 'use_kaggle': False, 'artifacts_root': WindowsPath('artifacts/asl_runs/hp-tuning')}
21:28:44 INFO - Class distribution (train): {'A': 300, 'B': 300, 'C': 300, 'D': 300, 'E': 300, 'F': 300, 'G': 300, 'H': 300, 'I': 300, 'J': 300, 'K': 300, 'L': 300, 'M': 300, 'N': 300, 'O': 300, 'P': 300, 'Q': 300, 'R': 300, 'S': 300, 'T': 300, 'U': 300, 'V': 300, 'W': 300, 'X': 300, 'Y': 300, 'Z': 300, 'del': 300, 'nothing': 300, 'space': 300}
21:28:44 INFO - Class distribution (val):   {'A': 300, 'B': 300, 'C': 300, 'D': 300, 'E': 300, 'F': 300, 'G': 300, 'H': 300, 'I': 300, 'J': 300, 'K': 300, 'L': 300, 'M': 300, 'N': 300, 'O': 300, 'P': 300, 'Q': 300, 'R': 300, 'S': 300, 'T': 300, 'U': 300, 'V': 300, 'W': 300, 'X': 300, 'Y': 300, 'Z': 300, 'del': 300, 'nothing': 300, 'space': 300}
21:28:46 INFO - Dataset sizes: train=8700, val=8700, test=26
21:28:46 INFO - Model: CNNSmall (blocks=4, act=relu)
21:28:46 INFO - Device: cuda
21:28:46 INFO - Epoch 1/10
21:29:24 INFO - Train: loss=2.1626 acc=0.4024 | Val: loss=1.5640 acc=0.4874 macroF1=0.4720                                                                                                                                 
21:29:25 INFO - New best macro-F1 0.4720 at epoch 1. Checkpoint saved.
21:29:25 INFO - Epoch 2/10
21:30:06 INFO - Train: loss=0.7155 acc=0.8202 | Val: loss=0.9044 acc=0.7077 macroF1=0.6959                                                                                                                                 
21:30:07 INFO - New best macro-F1 0.6959 at epoch 2. Checkpoint saved.
21:30:07 INFO - Epoch 3/10
21:30:45 INFO - Train: loss=0.2887 acc=0.9429 | Val: loss=0.3334 acc=0.9087 macroF1=0.9089                                                                                                                                 
21:30:45 INFO - New best macro-F1 0.9089 at epoch 3. Checkpoint saved.
21:30:45 INFO - Epoch 4/10
21:31:24 INFO - Train: loss=0.1427 acc=0.9747 | Val: loss=0.3729 acc=0.8684 macroF1=0.8643                                                                                                                                 
21:31:24 INFO - No improvement (1/3 patience).
21:31:24 INFO - Epoch 5/10
21:32:02 INFO - Train: loss=0.0836 acc=0.9856 | Val: loss=0.2786 acc=0.9147 macroF1=0.9082                                                                                                                                 
21:32:02 INFO - No improvement (2/3 patience).
21:32:02 INFO - Epoch 6/10
21:32:40 INFO - Train: loss=0.0546 acc=0.9923 | Val: loss=0.1061 acc=0.9751 macroF1=0.9751                                                                                                                                 
21:32:41 INFO - New best macro-F1 0.9751 at epoch 6. Checkpoint saved.
21:32:41 INFO - Epoch 7/10
21:33:19 INFO - Train: loss=0.0454 acc=0.9925 | Val: loss=0.0602 acc=0.9860 macroF1=0.9859                                                                                                                                 
21:33:20 INFO - New best macro-F1 0.9859 at epoch 7. Checkpoint saved.
21:33:20 INFO - Epoch 8/10
21:33:58 INFO - Train: loss=0.0304 acc=0.9959 | Val: loss=0.2096 acc=0.9320 macroF1=0.9337                                                                                                                                 
21:33:58 INFO - No improvement (1/3 patience).
21:33:58 INFO - Epoch 9/10
21:34:36 INFO - Train: loss=0.0443 acc=0.9911 | Val: loss=0.1261 acc=0.9651 macroF1=0.9649                                                                                                                                 
21:34:36 INFO - No improvement (2/3 patience).
21:34:36 INFO - Epoch 10/10
21:35:15 INFO - Train: loss=0.0394 acc=0.9933 | Val: loss=0.0679 acc=0.9834 macroF1=0.9835                                                                                                                                 
21:35:15 INFO - No improvement (3/3 patience).
21:35:15 INFO - Early stopping triggered.
21:35:15 INFO - Training completed. Artifacts at: artifacts\asl_runs\hp-tuning\2025-10-27_21-28-44__train-cnn_small_lr0.00107644_b64_bl4_act-relu_dr0.197358_ep10_sub300
[I 2025-10-27 21:35:15,792] Trial 17 finished with value: 0.9859056482772446 and parameters: {'lr': 0.0010764408093705184, 'weight_decay': 0.00013008367472836841, 'dropout': 0.19735802797784704, 'size': 96, 'subset_per_class': 300, 'num_blocks': 4, 'activation': 'relu', 'batch_size': 64}. Best is trial 1 with value: 0.9965513787447793.
21:35:15 INFO - 
===============
| ENSURE DATA |
===============
21:35:15 INFO - Wrote class mapping to data\class_indices.json
21:35:26 INFO - 
=========
| TRAIN |
=========
21:35:26 INFO - Args: {'train_dir': WindowsPath('data/asl_alphabet_train'), 'test_dir': WindowsPath('data/asl_alphabet_test'), 'val_ratio': 0.1, 'subset_per_class': 300, 'epochs': 10, 'batch_size': 128, 'lr': 0.0019150906751317963, 'weight_decay': 3.0381071382871777e-05, 'patience': 3, 'model': 'cnn_small', 'aug': False, 'size': 128, 'num_workers': 2, 'class_weights': False, 'dropout': 0.06960556139476864, 'num_blocks': 4, 'activation': 'gelu', 'seed': 42, 'use_kaggle': False, 'artifacts_root': WindowsPath('artifacts/asl_runs/hp-tuning')}
21:35:26 INFO - Class distribution (train): {'A': 300, 'B': 300, 'C': 300, 'D': 300, 'E': 300, 'F': 300, 'G': 300, 'H': 300, 'I': 300, 'J': 300, 'K': 300, 'L': 300, 'M': 300, 'N': 300, 'O': 300, 'P': 300, 'Q': 300, 'R': 300, 'S': 300, 'T': 300, 'U': 300, 'V': 300, 'W': 300, 'X': 300, 'Y': 300, 'Z': 300, 'del': 300, 'nothing': 300, 'space': 300}
21:35:26 INFO - Class distribution (val):   {'A': 300, 'B': 300, 'C': 300, 'D': 300, 'E': 300, 'F': 300, 'G': 300, 'H': 300, 'I': 300, 'J': 300, 'K': 300, 'L': 300, 'M': 300, 'N': 300, 'O': 300, 'P': 300, 'Q': 300, 'R': 300, 'S': 300, 'T': 300, 'U': 300, 'V': 300, 'W': 300, 'X': 300, 'Y': 300, 'Z': 300, 'del': 300, 'nothing': 300, 'space': 300}
21:35:28 INFO - Dataset sizes: train=8700, val=8700, test=26
21:35:28 INFO - Model: CNNSmall (blocks=4, act=gelu)
21:35:28 INFO - Device: cuda
21:35:28 INFO - Epoch 1/10
21:36:12 INFO - Train: loss=2.5284 acc=0.2615 | Val: loss=1.7344 acc=0.4867 macroF1=0.4500                                                                                                                                 
21:36:13 INFO - New best macro-F1 0.4500 at epoch 1. Checkpoint saved.
21:36:13 INFO - Epoch 2/10
21:36:57 INFO - Train: loss=1.0892 acc=0.6814 | Val: loss=0.8609 acc=0.7302 macroF1=0.7216                                                                                                                                 
21:36:58 INFO - New best macro-F1 0.7216 at epoch 2. Checkpoint saved.
21:36:58 INFO - Epoch 3/10
21:37:42 INFO - Train: loss=0.4771 acc=0.8775 | Val: loss=0.5467 acc=0.8262 macroF1=0.8220                                                                                                                                 
21:37:43 INFO - New best macro-F1 0.8220 at epoch 3. Checkpoint saved.
21:37:43 INFO - Epoch 4/10
21:38:28 INFO - Train: loss=0.2082 acc=0.9575 | Val: loss=0.2076 acc=0.9549 macroF1=0.9543                                                                                                                                 
21:38:28 INFO - New best macro-F1 0.9543 at epoch 4. Checkpoint saved.
21:38:28 INFO - Epoch 5/10
21:39:13 INFO - Train: loss=0.1079 acc=0.9829 | Val: loss=0.1729 acc=0.9629 macroF1=0.9629                                                                                                                                 
21:39:14 INFO - New best macro-F1 0.9629 at epoch 5. Checkpoint saved.
21:39:14 INFO - Epoch 6/10
21:39:59 INFO - Train: loss=0.0426 acc=0.9966 | Val: loss=0.0798 acc=0.9847 macroF1=0.9847                                                                                                                                 
21:39:59 INFO - New best macro-F1 0.9847 at epoch 6. Checkpoint saved.
21:39:59 INFO - Epoch 7/10
21:40:44 INFO - Train: loss=0.0244 acc=0.9984 | Val: loss=0.0459 acc=0.9914 macroF1=0.9914                                                                                                                                 
21:40:45 INFO - New best macro-F1 0.9914 at epoch 7. Checkpoint saved.
21:40:45 INFO - Epoch 8/10
21:41:30 INFO - Train: loss=0.0193 acc=0.9979 | Val: loss=0.1182 acc=0.9598 macroF1=0.9600                                                                                                                                 
21:41:30 INFO - No improvement (1/3 patience).
21:41:30 INFO - Epoch 9/10
21:42:14 INFO - Train: loss=0.0087 acc=0.9999 | Val: loss=0.0142 acc=0.9985 macroF1=0.9985                                                                                                                                 
21:42:15 INFO - New best macro-F1 0.9985 at epoch 9. Checkpoint saved.
21:42:15 INFO - Epoch 10/10
21:42:59 INFO - Train: loss=0.0038 acc=1.0000 | Val: loss=0.0109 acc=0.9978 macroF1=0.9978                                                                                                                                 
21:42:59 INFO - No improvement (1/3 patience).
21:42:59 INFO - Training completed. Artifacts at: artifacts\asl_runs\hp-tuning\2025-10-27_21-35-26__train-cnn_small_lr0.00191509_b128_bl4_act-gelu_dr0.0696056_ep10_sz128_sub300
[I 2025-10-27 21:42:59,576] Trial 18 finished with value: 0.9985058655810862 and parameters: {'lr': 0.0019150906751317963, 'weight_decay': 3.0381071382871777e-05, 'dropout': 0.06960556139476864, 'size': 128, 'subset_per_class': 300, 'num_blocks': 4, 'activation': 'gelu', 'batch_size': 128}. Best is trial 18 with value: 0.9985058655810862.
21:42:59 INFO - 
===============
| ENSURE DATA |
===============
21:42:59 INFO - Wrote class mapping to data\class_indices.json
21:43:10 INFO - 
=========
| TRAIN |
=========
21:43:10 INFO - Args: {'train_dir': WindowsPath('data/asl_alphabet_train'), 'test_dir': WindowsPath('data/asl_alphabet_test'), 'val_ratio': 0.1, 'subset_per_class': 300, 'epochs': 10, 'batch_size': 128, 'lr': 0.001907750412539486, 'weight_decay': 0.0007604080059821356, 'patience': 3, 'model': 'cnn_small', 'aug': False, 'size': 128, 'num_workers': 2, 'class_weights': False, 'dropout': 0.003964547607632277, 'num_blocks': 2, 'activation': 'gelu', 'seed': 42, 'use_kaggle': False, 'artifacts_root': WindowsPath('artifacts/asl_runs/hp-tuning')}
21:43:10 INFO - Class distribution (train): {'A': 300, 'B': 300, 'C': 300, 'D': 300, 'E': 300, 'F': 300, 'G': 300, 'H': 300, 'I': 300, 'J': 300, 'K': 300, 'L': 300, 'M': 300, 'N': 300, 'O': 300, 'P': 300, 'Q': 300, 'R': 300, 'S': 300, 'T': 300, 'U': 300, 'V': 300, 'W': 300, 'X': 300, 'Y': 300, 'Z': 300, 'del': 300, 'nothing': 300, 'space': 300}
21:43:10 INFO - Class distribution (val):   {'A': 300, 'B': 300, 'C': 300, 'D': 300, 'E': 300, 'F': 300, 'G': 300, 'H': 300, 'I': 300, 'J': 300, 'K': 300, 'L': 300, 'M': 300, 'N': 300, 'O': 300, 'P': 300, 'Q': 300, 'R': 300, 'S': 300, 'T': 300, 'U': 300, 'V': 300, 'W': 300, 'X': 300, 'Y': 300, 'Z': 300, 'del': 300, 'nothing': 300, 'space': 300}
21:43:11 INFO - Dataset sizes: train=8700, val=8700, test=26
21:43:11 INFO - Model: CNNSmall (blocks=2, act=gelu)
21:43:11 INFO - Device: cuda
21:43:11 INFO - Epoch 1/10
21:43:51 INFO - Train: loss=3.2135 acc=0.0587 | Val: loss=3.0575 acc=0.0745 macroF1=0.0303                                                                                                                                 
21:43:52 INFO - New best macro-F1 0.0303 at epoch 1. Checkpoint saved.
21:43:52 INFO - Epoch 2/10
21:44:31 INFO - Train: loss=2.8714 acc=0.1599 | Val: loss=2.7469 acc=0.1987 macroF1=0.1188                                                                                                                                 
21:44:32 INFO - New best macro-F1 0.1188 at epoch 2. Checkpoint saved.
21:44:32 INFO - Epoch 3/10
21:45:12 INFO - Train: loss=2.5139 acc=0.2636 | Val: loss=2.4957 acc=0.2253 macroF1=0.1812                                                                                                                                 
21:45:13 INFO - New best macro-F1 0.1812 at epoch 3. Checkpoint saved.
21:45:13 INFO - Epoch 4/10
21:45:54 INFO - Train: loss=2.2044 acc=0.3506 | Val: loss=2.0602 acc=0.3840 macroF1=0.3354                                                                                                                                 
21:45:55 INFO - New best macro-F1 0.3354 at epoch 4. Checkpoint saved.
21:45:55 INFO - Epoch 5/10
21:46:37 INFO - Train: loss=1.9757 acc=0.4079 | Val: loss=1.8988 acc=0.4295 macroF1=0.3843                                                                                                                                 
21:46:38 INFO - New best macro-F1 0.3843 at epoch 5. Checkpoint saved.
21:46:38 INFO - Epoch 6/10
21:47:19 INFO - Train: loss=1.7390 acc=0.4832 | Val: loss=1.7144 acc=0.4772 macroF1=0.4276                                                                                                                                 
21:47:20 INFO - New best macro-F1 0.4276 at epoch 6. Checkpoint saved.
21:47:20 INFO - Epoch 7/10
21:48:02 INFO - Train: loss=1.5557 acc=0.5492 | Val: loss=1.6514 acc=0.4789 macroF1=0.4557                                                                                                                                 
21:48:03 INFO - New best macro-F1 0.4557 at epoch 7. Checkpoint saved.
21:48:03 INFO - Epoch 8/10
21:48:44 INFO - Train: loss=1.4143 acc=0.5943 | Val: loss=1.4489 acc=0.5866 macroF1=0.5726                                                                                                                                 
21:48:45 INFO - New best macro-F1 0.5726 at epoch 8. Checkpoint saved.
21:48:45 INFO - Epoch 9/10
21:49:27 INFO - Train: loss=1.2706 acc=0.6461 | Val: loss=1.2533 acc=0.6359 macroF1=0.6269                                                                                                                                 
21:49:27 INFO - New best macro-F1 0.6269 at epoch 9. Checkpoint saved.
21:49:27 INFO - Epoch 10/10
21:50:09 INFO - Train: loss=1.1539 acc=0.6785 | Val: loss=1.3031 acc=0.5780 macroF1=0.5549                                                                                                                                 
21:50:09 INFO - No improvement (1/3 patience).
21:50:09 INFO - Training completed. Artifacts at: artifacts\asl_runs\hp-tuning\2025-10-27_21-43-10__train-cnn_small_lr0.00190775_b128_bl2_act-gelu_dr0.00396455_ep10_sz128_sub300
[I 2025-10-27 21:50:09,945] Trial 19 finished with value: 0.6268644661444733 and parameters: {'lr': 0.001907750412539486, 'weight_decay': 0.0007604080059821356, 'dropout': 0.003964547607632277, 'size': 128, 'subset_per_class': 300, 'num_blocks': 2, 'activation': 'gelu', 'batch_size': 128}. Best is trial 18 with value: 0.9985058655810862.
21:50:09 INFO - Best macro-F1: 0.9985 | Params: {'lr': 0.0019150906751317963, 'weight_decay': 3.0381071382871777e-05, 'dropout': 0.06960556139476864, 'size': 128, 'subset_per_class': 300, 'num_blocks': 4, 'activation': 'gelu', 'batch_size': 128}
21:50:09 INFO - Tuning complete. Artifacts saved to: artifacts\asl_runs\2025-10-27_19-40-08__tune-optuna-20trials
21:50:09 INFO - Next steps: Take the 'best.json' parameters and run train.py manually with --aug and without --aug.